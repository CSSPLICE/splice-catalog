[
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/Project?id=321",
    "resource_url_type": "URL",
    "bibtex_source": "@data{iSnap15,\nurl = {https://pslcdatashop.web.cmu.edu/Project?id=321},\nauthor = {Thomas Price},\npublisher = {DataShop},\ntitle = {iSnap},\nyear = {N/A}, \nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "iSnap - Introductory Programming",
    "creator": "Price, Thomas",
    "given_name": "Thomas",
    "family_name": "Price",
    "name_identifier": "https://orcid.org/0000-0001-9375-2292",
    "affiliation": "North Carolina State University ",
    "availability": "open",
    "format": "txt",
    "programming_language": "Snap!",
    "data_collection_start_date": 2015,
    "data_collection_end_date": 2017,
    "publication_year": null,
    "number_of_semesters": 5,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "log data",
    "data_processing": null,
    "population": "CS0 (non-majors)",
    "units_number": "F15: 84243; F16: 208105; S16: 172160; F17: 161255; S17: 140581; Total: 766344",
    "task_number": "6 assignments",
    "sample_size": "~350",
    "sample_demographics": "Introductory Computing Students",
    "country": "USA",
    "educational_institution": "NCSU",
    "data_standard": "ProgSnap",
    "learning_environment": "iSnap",
    "aggregation": "Yes",
    "aggregation_level": "Complete snapshot; Detailed Log",
    "related_publication_url": "Price et al. 2017",
    "related_publication": "@inproceedings{price2017isnap,\n  title={iSnap: towards intelligent tutoring in novice programming environments},\n  author={Price, Thomas W and Dong, Yihuan and Lipovac, Dragan},\n  booktitle={Proceedings of the 2017 ACM SIGCSE Technical Symposium on computer science education},\n  pages={483--488},\n  year={2017}\n}",
    "rights": null,
    "description": "\"iSnap logs all student actions to a remote database, including any interactions with the user interface and coding\narea. It also logs complete snapshots of students’ code after each edit, allowing for complete replay of a student’s\nactions within the environment. Each entry in iSnap’s logs\nconsists of an event type (e.g. “block grabbed”, “project exported”), any associated data (e.g. an ID for the grabbed\nblock) and an updated snapshot of the student’s code (if\nchanged). While this data could have many uses, we use it\nspecifically to automatically generate contextual hints\"",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility:  0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "GitHub",
    "resource_url": "https://github.com/TUDelftScratchLab/ScratchDataset",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Aivaloglou17,\nurl = {https://github.com/TUDelftScratchLab/ScratchDataset},\nauthor = {Fenia Aivaloglou},\npublisher = {Github},\ntitle = {Scratch Dataset},\nyear = {2017}, \nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Scratch Dataset",
    "creator": "Aivaloglou, Fenia",
    "given_name": "Fenia",
    "family_name": "Aivaloglou",
    "name_identifier": "https://orcid.org/0000-0002-6531-2166",
    "affiliation": "Open Universiteit",
    "availability": "open",
    "format": "JSON",
    "programming_language": "Scratch",
    "data_collection_start_date": 2016,
    "data_collection_end_date": null,
    "publication_year": 2017,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "log data",
    "data_processing": "1) list of used blocks per project, within the sprite, and the stage of the project",
    "population": null,
    "units_number": null,
    "task_number": null,
    "sample_size": 109960,
    "sample_demographics": "All Ages",
    "country": "International",
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": "Scratch",
    "aggregation": "Yes",
    "aggregation_level": "Blocks used",
    "related_publication_url": "Aivaloglou et al. 2017",
    "related_publication": "@inproceedings{aivaloglou2017dataset,\n  title={A dataset of scratch programs: scraped, shaped and scored},\n  author={Aivaloglou, Efthimia and Hermans, Felienne and Moreno-Le{\\'o}n, Jes{\\'u}s and Robles, Gregorio},\n  booktitle={2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR)},\n  pages={511--514},\n  year={2017},\n  organization={IEEE}\n}",
    "rights": null,
    "description": "\"A dataset of 250K recent Scratch projects from 100K different authors scraped from the Scratch project repository. We processed the projects' source code and metadata to encode them into a database that facilitates querying and further analysis\"",
    "research_question": null,
    "future_work": "1) assessment of the programming skills that novice programmers develop in the Scratch environment\n2) quality of the programming artifacts developed in the Scratch environment",
    "fairness_score": "Total score: 27% (initial)\nFindability:  2.5 of 7\nAccessibility:  1 of 3\nInteroperability: 0 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Code.org",
    "resource_url": "https://code.org/files/anonymizeddata.zip",
    "resource_url_type": "URL",
    "bibtex_source": "@data{hourOfCode,\n author = {Piech, Chris},\ntitle = {{Hour of Code 2013}},\nurl = {https://code.org/files/anonymizeddata.zip},\npublisher = {Code.org}, \nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Hour of Code 2013",
    "creator": "Piech, Chris",
    "given_name": "Chris",
    "family_name": "Piech",
    "name_identifier": "https://orcid.org/0000-0001-5140-0467",
    "affiliation": "Stanford University",
    "availability": "open",
    "format": "JSON, txt",
    "programming_language": null,
    "data_collection_start_date": 2013,
    "data_collection_end_date": 2014,
    "publication_year": null,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Partial solutions (Abstract Syntax tree)",
    "measurement_type": "log data",
    "data_processing": null,
    "population": "General open (5 to 98 years old)",
    "units_number": "137M",
    "task_number": 2,
    "sample_size": "~90k",
    "sample_demographics": "All Ages",
    "country": "International",
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": "Scratch",
    "aggregation": "Yes",
    "aggregation_level": "--",
    "related_publication_url": "Piech et al. 2015",
    "related_publication": "@inproceedings{piech2015autonomously,\n  title={Autonomously generating hints by inferring problem solving policies},\n  author={Piech, Chris and Sahami, Mehran and Huang, Jonathan and Guibas, Leonidas},\n  booktitle={Proceedings of the second (2015) acm conference on learning@ scale},\n  pages={195--204},\n  year={2015}\n}",
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 18% (initial)\nFindability:  1.5 of 7\nAccessibility: 1 of 3\nInteroperability: 0 of 4\nReusability: 2 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Harvard Dataverse",
    "resource_url": "https://doi.org/10.7910/DVN/NMEM7D",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{DVN/NMEM7D_2022,\nauthor = {Weegar, Rebecka},\npublisher = {Harvard Dataverse},\ntitle = {{ShortAnswersIDSV}},\nUNF = {UNF:6:bjoE0zt+1wGKhLfGuFSOgw==},\nyear = {2022},\nversion = {V1},\ndoi = {10.7910/DVN/NMEM7D},\nurl = {https://doi.org/10.7910/DVN/NMEM7D}, \nnote = {Last Access: 5 February, 2024},\n}",
    "title": "ShortAnswersIDSV",
    "creator": "Weegar, Rebecka",
    "given_name": "Rebecka",
    "family_name": "Weegar",
    "name_identifier": null,
    "affiliation": "Umeå University",
    "availability": "open",
    "format": "tsv",
    "programming_language": null,
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2022,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Short answers",
    "measurement_type": "Exam questions",
    "data_processing": null,
    "population": "CS-1",
    "units_number": 15768,
    "task_number": 64,
    "sample_size": null,
    "sample_demographics": null,
    "country": null,
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": null,
    "related_publication": null,
    "rights": "CC0 1.0 Universal",
    "description": "This data set contains exam questions and answers from an introductory course to computer science",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 79% (moderate)\nFindability:  7 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 7 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataverseNO",
    "resource_url": "https://doi.org/10.18710/O8FCIK",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{O8FCIK_2021,\nauthor = {Lorås, Madeleine and Riese, Emma and Ukrop, Martin and Effenberger, Tomáš},\npublisher = {DataverseNO},\ntitle = {{Supplementary data for study: Challenges Faced by Teaching Assistants in Computer Science Education Across Europe}},\nUNF = {UNF:6:DLTg6jcGGlTVXf+ont4Ecg==},\nyear = {2021},\nversion = {V1},\ndoi = {10.18710/O8FCIK},\nurl = {https://doi.org/10.18710/O8FCIK}, \nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Supplementary data for study: Challenges Faced by Teaching Assistants in Computer Science Education Across Europe",
    "creator": "Lorås, Madeleine; Riese, Emma; Ukrop, Martin; Effenberger, Tomáš",
    "given_name": "Madeleine; Emma; Martin; Tomáš",
    "family_name": "Lorås; Riese; Ukrop; Effenberger",
    "name_identifier": null,
    "affiliation": "Norwegian University of Science and Technology, Trondheim, Norway; KTH Royal Institute of Technology, Stockholm, Sweden; Masaryk University, Brno, Czech Rep; Masaryk University, Brno, Czech Rep",
    "availability": "open",
    "format": "tsv, txt",
    "programming_language": null,
    "data_collection_start_date": 2018,
    "data_collection_end_date": 2020,
    "publication_year": 2021,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Reflective Essay",
    "measurement_type": null,
    "data_processing": null,
    "population": "Introductory TA course for CS",
    "units_number": 180,
    "task_number": 1,
    "sample_size": 180,
    "sample_demographics": null,
    "country": "Norway; Sweden; Czech Republic",
    "educational_institution": "NTNU, KTH, MUNI",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": "Riese et al. 2021",
    "related_publication": "@inproceedings{10.1145/3430665.3456304,\nauthor = {Riese, Emma and Lor\\r{a}s, Madeleine and Ukrop, Martin and Effenberger, Tom\\'{a}\\v{s}},\ntitle = {Challenges Faced by Teaching Assistants in Computer Science Education Across Europe},\nyear = {2021},\nisbn = {9781450382144},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3430665.3456304},\ndoi = {10.1145/3430665.3456304},\nbooktitle = {Proceedings of the 26th ACM Conference on Innovation and Technology in Computer Science Education V. 1},\npages = {547–553},\nnumpages = {7},\nkeywords = {TAs, teaching assistants, challenges},\nlocation = {Virtual Event, Germany},\nseries = {ITiCSE '21}\n}",
    "rights": "CC0 1.0 Universal",
    "description": "This data includes the themes, sub-themes, codes and exemplary quotes from the analysis of reflection essays for the study \"Challenges Faced by TAs in CS Education Across Europe\". ",
    "research_question": "(RQ1)Which challenges do TAs in computer science face?\n(RQ2) Are the identified challenges similar or different across institutions and countries?",
    "future_work": null,
    "fairness_score": "Total score: 75% (moderate)\nFindability:  7 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 6 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=2865",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Rivers_2016,\nurl = {https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1801},\nauthor = {Kelly Rivers},\npublisher = {DataShop},\ntitle = {ICER - First Attempts - Modified Steps - ITAP Goal},\nyear = {2016}, \nnote = {Last Access: 5 February, 2024},\n}",
    "title": "CSEDM 2019 Data Challenge",
    "creator": "Rivers, Kelly",
    "given_name": "Kelly",
    "family_name": "Rivers",
    "name_identifier": "https://orcid.org/0000-0002-7004-8080",
    "affiliation": "Carnegie Mellon University: Pittsburgh, PA, US",
    "availability": "open (through signup on Datashop)",
    "format": "csv",
    "programming_language": "Python",
    "data_collection_start_date": 2016,
    "data_collection_end_date": 2016,
    "publication_year": 2019,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "Knowledge Tracing",
    "data_processing": null,
    "population": "Students ",
    "units_number": 18833,
    "task_number": 38,
    "sample_size": 89,
    "sample_demographics": "two introductory programming course students",
    "country": "USA",
    "educational_institution": "Carnegie Mellon University",
    "data_standard": 0,
    "learning_environment": "ITAP intelligent tutoring system",
    "aggregation": "yes",
    "aggregation_level": "Submissions/Hint events",
    "related_publication_url": "https://dl.acm.org/doi/10.1145/2960310.2960333",
    "related_publication": "@inproceedings{10.1145/2960310.2960333,\nauthor = {Rivers, Kelly and Harpstead, Erik and Koedinger, Ken},\ntitle = {Learning Curve Analysis for Programming: Which Concepts do Students Struggle With?},\nyear = {2016},\nisbn = {9781450344494},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2960310.2960333},\ndoi = {10.1145/2960310.2960333},\nabstract = {The recent surge in interest in using educational data mining on student written programs has led to discoveries about which compiler errors students encounter while they are learning how to program. However, less attention has been paid to the actual code that students produce. In this paper, we investigate programming data by using learning curve analysis to determine which programming elements students struggle with the most when learning in Python. Our analysis extends the traditional use of learning curve analysis to include less structured data, and also reveals new possibilities for when to teach students new programming concepts. One particular discovery is that while we find evidence of student learning in some cases (for example, in function definitions and comparisons), there are other programming elements which do not demonstrate typical learning. In those cases, we discuss how further changes to the model could affect both demonstrated learning and our understanding of the different concepts that students learn.},\nbooktitle = {Proceedings of the 2016 ACM Conference on International Computing Education Research},\npages = {143–151},\nnumpages = {9},\nkeywords = {educational data mining, knowledge components, learning curve analysis, programming syntax},\nlocation = {Melbourne, VIC, Australia},\nseries = {ICER '16}\n}",
    "rights": 0,
    "description": "The dataset used in the challenge comes from a study of novice Python \nprogrammers working with the ITAP intelligent tutoring system. For \nmore information on the original experiment, see . There are 89 total\n students represented, and they worked on 38 problems over time. The \nstudy lasted over 7 weeks. The students could attempt the problems in \nany order, though there was a default order. Students could attempt the \nproblem any number of times, receiving feedback from test cases each \ntime, and they could also request hints from ITAP (though access was \nlimited for students, depending on the week and their experimental \ncondition). The dataset itself contains a record for each attempt and \nhint request that students made while working.",
    "research_question": "What are the KCs (Knowledge components) of programming? \nWhat are the steps and opportunities in a programming problem?\nHow should correctness be measured for each of these steps?",
    "future_work": "In future work, we plan to modify the KCs used in the models we’ve generated to see if we can improve the modeling of the student data. ",
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=3458",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Shaffer_2019,\nurl = {https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=3458},\nauthor = {Cliff Shaffer},\npublisher = {DataShop},\ntitle = {CodeWorkout data Spring 2019},\nyear = {2019}, \nnote = {Last Access: 5 February, 2024},\n}",
    "title": "CodeWorkout data Spring 2019",
    "creator": "Shaffer, Cliff",
    "given_name": "Cliff",
    "family_name": "Shaffer",
    "name_identifier": "https://orcid.org/0000-0003-0001-0295",
    "affiliation": "Virginia Tech",
    "availability": "open (through signup on Datashop)",
    "format": "csv",
    "programming_language": "Java",
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2019,
    "publication_year": 2019,
    "number_of_semesters": 2,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "log data",
    "data_processing": "No",
    "population": "CS-1",
    "units_number": "Sp: 201570",
    "task_number": 50,
    "sample_size": 413,
    "sample_demographics": "one course, two sections; cs1 students; USA",
    "country": "USA",
    "educational_institution": 0,
    "data_standard": "ProgSnap 2",
    "learning_environment": "CodeWorkout",
    "aggregation": 0,
    "aggregation_level": "Compilation/Run",
    "related_publication_url": "https://dl.acm.org/doi/abs/10.1145/3059009.3059055",
    "related_publication": "@inproceedings{10.1145/3059009.3059055,\nauthor = {Edwards, Stephen H. and Murali, Krishnan Panamalai},\ntitle = {CodeWorkout: Short Programming Exercises with Built-in Data Collection},\nyear = {2017},\nisbn = {9781450347044},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3059009.3059055},\ndoi = {10.1145/3059009.3059055},\nabstract = {Learning programming techniques can be challenging and frustrating for many students. Many instructors use drill-and-practice strategies to help students develop basic programming techniques and improve their confidence. Online systems that provide short programming exercises with immediate, automated feedback are often seen as a valuable approach to drill-and-practice. However, the relationship between practicing with short programming exercises and performance on larger programming assignments or exams is unclear. This paper describes CodeWorkout, an open-source drill-and-practice system that supports short programming exercises and multiple choice questions. CodeWorkout combines an open, gradual engagement model that allows any student to practice exercises, whether or not they have an account or are enrolled in a course, together with powerful course management features that support graded assignments, quizzes, and even practicum style exams. It also provides a rich data collection and evaluation infrastructure for educational research purposes. We report on initial experiences using CodeWorkout in a CS1 course, including student perceptions of the tool and its benefits.},\nbooktitle = {Proceedings of the 2017 ACM Conference on Innovation and Technology in Computer Science Education},\npages = {188–193},\nnumpages = {6},\nkeywords = {skill development, practice, homework, exam, coding, codeworkout},\nlocation = {Bologna, Italy},\nseries = {ITiCSE '17}\n}",
    "rights": 0,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataVerseNO",
    "resource_url": "https://doi.org/10.18710/MWLHOA",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{MWLHOA_2021,\nauthor = {Lorås, Madeleine},\npublisher = {DataverseNO},\ntitle = {{Supplementary data for study: Understanding the Relation Between Study Behaviors and Educational Design (Study 1)}},\nUNF = {UNF:6:7HEHyifDmf5Dx/Ulb9Sdfg==},\nyear = {2021},\nversion = {V1},\ndoi = {10.18710/MWLHOA},\nurl = {https://doi.org/10.18710/MWLHOA}, \nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Supplementary data for study: Understanding the Relation Between Study Behaviors and Educational Design (Study 1)",
    "creator": "Lorås, Madeleine",
    "given_name": "Madeleine",
    "family_name": "Lorås",
    "name_identifier": "https://orcid.org/0000-0003-4152-775X",
    "affiliation": "Norwegian University of Science and Technology",
    "availability": "open",
    "format": "csv, txt",
    "programming_language": null,
    "data_collection_start_date": 2017,
    "data_collection_end_date": 2018,
    "publication_year": 2021,
    "number_of_semesters": 2,
    "data_protection": "Anonymized",
    "data_type": "Characteristics of CS programs in Norway",
    "measurement_type": "Doucument analyis using a survey",
    "data_processing": "analyze webpages of programs and add it to a survey; national databases review",
    "population": "Norwegian undergraduate programs",
    "units_number": 56,
    "task_number": null,
    "sample_size": "12 institutions; 56 programs",
    "sample_demographics": "Norway",
    "country": "Norway",
    "educational_institution": "12 instituitions in Norway",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": "Lorås et al. 2018; Lorås, Madeleine",
    "related_publication": "@article{loraas2018first,\n  title={First year computer science education in Norway},\n  author={Lor{\\aa}s, Madeleine and Sindre, Guttorm and Aalberg, Trond},\n  year={2018},\n  publisher={Bibsys Open Journal Systems}\n}; @article{loraas2021understanding,\n  title={Understanding the Relation Between Study Behaviors and Educational Design: Research in Computing Education},\n  author={Lor{\\aa}s, Madeleine},\n  year={2021},\n  publisher={NTNU}\n}",
    "rights": "CC0 1.0 Universal",
    "description": "It has been identified that the first-year experience is crucial to student motivation and throughput of study programs, therefore it is interesting to look at the state of the art of computer science study programs in Norway. This data is part of a PhD project and relates to Study 1. In this study we present a survey and study of the number of undergraduate computer science programs in Norway and map their characteristics in order to gather an up to date overview of the selection of programs. Through a systematic review of all Norwegian undergraduate programs using data from national databases we have found that there are 12 institutions offering 56 different programs in Norway in 2018. The study showed that the characteristics of these programs vary, that is, the amount of computer science courses during the first year, the number of students, admission requirements, student satisfaction and time commitment. This article presents these findings along with an analysis of what characteristics impact the students’ contentment and learning experience. ",
    "research_question": "What characterizes the first year of computer science study programs in Norway? How are they designed? What impacts student contentment and learning experience? ",
    "future_work": " Further research is needed to deepen the understanding of what affects the students’ contentment and time commitment. For example, additional research using individual data should be conducted. This research should focus on gender unbalance, factors impacting student satisfaction and further exploration of time commitment as an indicator for study quality. Additionally, there are variables not included in this study that could also be interesting to investigate, such as degree of completion and performance in the job marked. ",
    "fairness_score": "Total score: 75% (moderate)\nFindability: 7 of 7\nAccessibility: 2 of 3\nInteroperability: 2 of 4\nReusability: 7 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "GitHub",
    "resource_url": "https://github.com/Microsoft/Code-Hunt",
    "resource_url_type": "URL",
    "bibtex_source": "@data {Microsoft_2015,\nurl = {https://github.com/Microsoft/Code-Hunt},\nauthor = {Bishop, Judith and Horspool, R Nigel and Xie, Tao and Tillmann, Nikolai and De Halleux, Jonathan\n},\npublisher = {GitHub},\ntitle = {Code Hunt},\nyear = {2015}, \nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Code Hunt",
    "creator": "Bishop, Judith; Horspool, R Nigel; Xie, Tao; Tillmann, Nikolai; De Halleux, Jonathan",
    "given_name": "Judith; R Nigel; Tao; Nikolai; Jonathan",
    "family_name": "Bishop; Horspool; Xie; Tillmann; De Halleux",
    "name_identifier": null,
    "affiliation": "Microsoft Research",
    "availability": "open",
    "format": ".cs, .java",
    "programming_language": "Java & C#",
    "data_collection_start_date": 0,
    "data_collection_end_date": 0,
    "publication_year": 2015,
    "number_of_semesters": 0,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "code solutions",
    "data_processing": "code samples",
    "population": null,
    "units_number": "13K",
    "task_number": 24,
    "sample_size": 250,
    "sample_demographics": "Students and enthusiasts of codehunt",
    "country": 0,
    "educational_institution": 0,
    "data_standard": 0,
    "learning_environment": "CodeHunt",
    "aggregation": "No",
    "aggregation_level": "Submissions",
    "related_publication_url": "https://ieeexplore.ieee.org/abstract/document/7202990?casa_token=VqEAsA_0XW4AAAAA:NUQVMnkSgFrNYvq8XgbHS1RJ9hqhib2wdZC9hxZrf594QI6Y-quvymi2_8_U1Ovgo7YZJNZP",
    "related_publication": "@inproceedings{bishop2015code,\n  title={Code Hunt: Experience with coding contests at scale},\n  author={Bishop, Judith and Horspool, R Nigel and Xie, Tao and Tillmann, Nikolai and De Halleux, Jonathan},\n  booktitle={2015 IEEE/ACM 37th IEEE International Conference on Software Engineering},\n  volume={2},\n  pages={398--407},\n  year={2015},\n  organization={IEEE}\n}",
    "rights": "Microsoft Research Data License Agreement",
    "description": "Code Hunt is a serious education game which has been played by over 140,000 students and enthusiasts over the past year. In the process we have collected over 1.5M programs, which we can link to specific users at specific levels of expertise. We hope that researchers will embark on research into the data, discovering how coders code and how technology can be used to make the process more accurate and less painful. Although there has been research on how students code in the past, Microsoft Research is offering a unique opportunity to conduct research on large, common data sets. This preview data set contains the programs written by students (only) worldwide during a contest over 48 hours. There are approximately 250 users, 24 puzzles and about 13,000 programs. ",
    "research_question": "N/A - description and experience Codehunt offers",
    "future_work": "allow Python solutions; add hints for learners;",
    "fairness_score": "Total score: 27% (initial)\nFindability:  2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 0 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "ACM Digital Library",
    "resource_url": "https://bluej.org/blackbox/#AccessBlueJ",
    "resource_url_type": "URL",
    "bibtex_source": "@data{bluejBlackbox,\nauthor = {Michael Kölling; Ian Utting; Davin McCall; Neil Brown; Amjad Altadmri; Hamza Hamza},\ntitle = {{B}lackbox --- bluej.org},\nurl = {https://bluej.org/blackbox/},\nyear = {},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Blackbox",
    "creator": "Kölling, Michael; Utting, Ian; McCall, Davin; Brown, Neil; Altadmri, Amjad; Hamza, Hamza",
    "given_name": "Michael; Ian; Davin; Neil; Amjad; Hamza",
    "family_name": "Kolling; Utting; McCall; Brown; Altadmri; Hamza",
    "name_identifier": "https://orcid.org/0000-0003-0544-2003 ",
    "affiliation": "BlueJ",
    "availability": "By request",
    "format": 0,
    "programming_language": "Java",
    "data_collection_start_date": 2013,
    "data_collection_end_date": 0,
    "publication_year": null,
    "number_of_semesters": 0,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "code solutions and logs",
    "data_processing": 0,
    "population": 0,
    "units_number": 0,
    "task_number": 0,
    "sample_size": "1M",
    "sample_demographics": 0,
    "country": 0,
    "educational_institution": 0,
    "data_standard": 0,
    "learning_environment": "BlueJ",
    "aggregation": 0,
    "aggregation_level": "Line Edits",
    "related_publication_url": "https://dl.acm.org/doi/10.1145/2538862.2538924",
    "related_publication": "@inproceedings{10.1145/2538862.2538924,\nauthor = {Brown, Neil Christopher Charles and K\\\"{o}lling, Michael and McCall, Davin and Utting, Ian},\ntitle = {Blackbox: a large scale repository of novice programmers' activity},\nyear = {2014},\nisbn = {9781450326056},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2538862.2538924},\ndoi = {10.1145/2538862.2538924},\nabstract = {Automatically observing and recording the programming behaviour of novices is an established computing education research technique. However, prior studies have been conducted at a single institution on a small or medium scale, without the possibility of data re-use. Now, the widespread availability of always-on Internet access allows for data collection at a much larger, global scale. In this paper we report on the Blackbox project, begun in June 2013. Blackbox is a perpetual data collection project that collects data from worldwide users of the BlueJ IDE -- a programming environment designed for novice programmers. Over one hundred thousand users have already opted-in to Blackbox. The collected data is anonymous and is available to other researchers for use in their own studies, thus benefitting the larger research community. In this paper, we describe the data available via Blackbox, show some examples of analyses that can be performed using the collected data, and discuss some of the analysis challenges that lie ahead.},\nbooktitle = {Proceedings of the 45th ACM Technical Symposium on Computer Science Education},\npages = {223–228},\nnumpages = {6},\nkeywords = {programming education, data collection, blackbox, BlueJ},\nlocation = {Atlanta, Georgia, USA},\nseries = {SIGCSE '14}\n}; \n@inproceedings{10.1145/3230977.3230991,\nauthor = {Brown, Neil C. C. and Altadmri, Amjad and Sentance, Sue and K\\\"{o}lling, Michael},\ntitle = {Blackbox, Five Years On: An Evaluation of a Large-scale Programming Data Collection Project},\nyear = {2018},\nisbn = {9781450356282},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3230977.3230991},\ndoi = {10.1145/3230977.3230991},\nabstract = {The Blackbox project has been collecting programming activity data from users of BlueJ (a novice-targeted Java development environment) for nearly five years. The resulting dataset of more than two terabytes of data has been made available to interested researchers from the outset. In this paper, we assess the impact of the Blackbox project: we perform a mapping study to assess eighteen publications which have made use of the Blackbox data, and we report on the advantages and difficulties experienced by researchers working with this data, collected via a survey. We find that Blackbox has enabled pieces of research which otherwise would not have been possible, but there remain technical challenges in the analysis. Some of these -- but not all -- relate to the scale of the data. We provide suggestions for the future use of Blackbox, and reflections on the role of such data collection projects in programming research.},\nbooktitle = {Proceedings of the 2018 ACM Conference on International Computing Education Research},\npages = {196–204},\nnumpages = {9},\nkeywords = {blackbox, mapping study, shared data},\nlocation = {Espoo, Finland},\nseries = {ICER '18}\n}",
    "rights": 0,
    "description": "Blackbox is a perpetual data collection project that collects data from worldwide users of the BlueJ IDE -- a programming environment designed for novice programmers. Over one hundred thousand users have already opted-in to Blackbox. The collected data is anonymous and is available to other researchers for use in their own studies, thus benefitting the larger research community.",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Harvard Dataverse",
    "resource_url": "https://doi.org/10.7910/DVN/6BPCXN",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{DVN/6BPCXN_2022,\nauthor = {Edwards, John},\npublisher = {Harvard Dataverse},\ntitle = {{2019 CS1 Keystroke Data}},\nUNF = {UNF:6:RbWfgdjzTbDJOY7Eyhen9w==},\nyear = {2022},\nversion = {DRAFT VERSION},\ndoi = {10.7910/DVN/6BPCXN},\nurl = {https://doi.org/10.7910/DVN/6BPCXN},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "2019 CS1 Keystroke Data",
    "creator": "Edwards, John",
    "given_name": "John",
    "family_name": "Edwards",
    "name_identifier": "https://orcid.org/0000-0002-1215-976X",
    "affiliation": "Utah State University",
    "availability": "open",
    "format": "csv",
    "programming_language": "Python",
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2019,
    "publication_year": 2019,
    "number_of_semesters": 2,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "log data",
    "data_processing": null,
    "population": "CS-1",
    "units_number": "5M",
    "task_number": "10 (5 part)",
    "sample_size": 505,
    "sample_demographics": "USA",
    "country": "USA",
    "educational_institution": "Utah State University",
    "data_standard": "ProgSnap 2",
    "learning_environment": null,
    "aggregation": "yes",
    "aggregation_level": "Keystroke",
    "related_publication_url": "https://doi.org/10.1145/3372782.3406272",
    "related_publication": "@inproceedings{10.1145/3372782.3406272,\nauthor = {Edwards, John and Leinonen, Juho and Birthare, Chetan and Zavgorodniaia, Albina and Hellas, Arto},\ntitle = {Programming Versus Natural Language: On the Effect of Context on Typing in CS1},\nyear = {2020},\nisbn = {9781450370929},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3372782.3406272},\ndoi = {10.1145/3372782.3406272},\nabstract = {Analyzing keystroke data from students working on essay and programming tasks, we study to what extent the difference in task context influences performance in typing. Using data from two introductory programming courses offered at two separate institutions, we compare and contrast typing speed between programming and natural language tasks. We observe that students tend to be faster at typing (the same) character pairs when writing natural language text than when learning to write code. We show that students improve on typing character pairs that appear in frequently used words in programming languages, and that typing programming constructs also improves. We find that students are faster at detecting and erasing their mistakes when typing natural language text than when programming. Our results support theories regarding contextual memory, procedural memory, and practice, and have implications for course curriculum and pedagogy design.},\nbooktitle = {Proceedings of the 2020 ACM Conference on International Computing Education Research},\npages = {204–215},\nnumpages = {12},\nkeywords = {cognitive load, memory context, procedural memory, schemas, typing},\nlocation = {Virtual Event, New Zealand},\nseries = {ICER '20}\n}\n\n  ",
    "rights": "CC0 1.0",
    "description": "Keystroke data collected from CS1 student participants during 2019 at Utah State University. See readme.txt for detailed information.\n\nThis dataset has undergone deidentification, though it is possible, being a complex, temporal, and ephemeral dataset, that identifying keystrokes may have been missed. Ethical use of this dataset includes avoiding attempts at reconstructing identities. That said, if researchers discover anything identifiable in the data, they are encouraged to contact the dataset authors (john.edwards@usu.edu). ",
    "research_question": "RQ1 How does context influence the typing speed of computer\nsource code and written language?\nRQ2 How does the typing speed of programming language con-\nstructs evolve over time?\nRQ3 How does the number of typing mistakes while program-\nming evolve and how does the speed at which students cor-\nrect mistakes differ between programming and writing nat-\nural language?",
    "future_work": "New research directions regarding the use of keystroke data, for example, modeling the practice that individual\nstudents or groups of students need to become proficient with syntax.",
    "fairness_score": "Total score: 60% (moderate)\nFindability:  6.5 of 7\nAccessibility: 1 of 3\nInteroperability: 3 of 4\nReusability: 4 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Harvard Dataverse",
    "resource_url": "https://doi.org/10.7910/DVN/BVOF7S",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{DVN/BVOF7S_2022,\nauthor = {Edwards, John},\npublisher = {Harvard Dataverse},\ntitle = {{2021 CS1 Keystroke Data}},\nUNF = {UNF:6:kZHlhwSV+sTIdRt6Sc/4gw==},\nyear = {2022},\nversion = {V6},\ndoi = {10.7910/DVN/BVOF7S},\nurl = {https://doi.org/10.7910/DVN/BVOF7S},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "2021 CS1 Keystroke Data",
    "creator": "Edwards, John",
    "given_name": "John",
    "family_name": "Edwards",
    "name_identifier": "https://orcid.org/0000-0002-1215-976X",
    "affiliation": "Utah State University",
    "availability": "open",
    "format": "csv, pdf, py, tsv",
    "programming_language": "Python",
    "data_collection_start_date": 2021,
    "data_collection_end_date": 2021,
    "publication_year": 2022,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "log data",
    "data_processing": null,
    "population": " CS-1",
    "units_number": 1048575,
    "task_number": "13 (8 part)",
    "sample_size": 44,
    "sample_demographics": "USA",
    "country": "USA",
    "educational_institution": "Utah State University",
    "data_standard": "ProgSnap 2",
    "learning_environment": null,
    "aggregation": "yes",
    "aggregation_level": "Keystroke",
    "related_publication_url": "https://doi.org/10.5281/zenodo.7646659",
    "related_publication": "@article{edwards2023review,\n  author       = {Edwards, John and\n                  Hart, Kaden and\n                  Shrestha, Raj},\n  title        = {{Review of CSEDM Data and Introduction of Two \n                   Public CS1 Keystroke Datasets}},\n  journal      = {Journal of Educational Data Mining},\n  year         = 2023,\n  volume       = 15,\n  number       = 1,\n  month        = mar,\n  Pages.       = {1-31},\n  doi          = {10.5281/zenodo.7646659},\n  url          = {https://doi.org/10.5281/zenodo.7646659}\n}",
    "rights": null,
    "description": "Keystroke data collected from CS1 student participants during fall 2021 \nsemester at Utah State University. See readme.txt for detailed \ninformation. \n\nThis dataset has undergone deidentification, though\n it is possible, being a complex, temporal, and ephemeral dataset, that \nidentifying keystrokes may have been missed. Ethical use of this dataset\n includes avoiding attempts at reconstructing identities. That said, if \nresearchers discover anything identifiable in the data, they are \nencouraged to contact the dataset authors (john.edwards@usu.edu).\n                                                                    ",
    "research_question": "What are methods and challenges when creating dataset for keystroke data?",
    "future_work": "1. To what extent are cooperative and collaborative learning activities/scenarios part of courses that aim to teach programming or improve students' programming skills?\\newline 2. What goals are pursued in connection with cooperative and collaborative learning activities?",
    "fairness_score": "Total score: 79% (moderate)\nFindability: 7 of 7\nAccessibility:  2 of 3\nInteroperability: 3 of 4\nReusability: 7 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "GitHub",
    "resource_url": "https://github.com/daveho/CloudCoder",
    "resource_url_type": "URL",
    "bibtex_source": "@data{cloudcoder,\nauthor = {Spacco, Jaime;  Hovemeyer, David;  Bonner, Shane; Lefever, Jason; Garcia, Sat; Mount, Sarah},\ntitle = {CloudCoder},\nurl = {https://github.com/daveho/CloudCoder},\nyear = {2013},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "CloudCoder",
    "creator": "Spacco, Jaime;  Hovemeyer, David;  Bonner, Shane; Lefever, Jason; Garcia, Sat; Mount, Sarah",
    "given_name": "Jaime;  David;  Shane; Jason; Sat; Sarah",
    "family_name": "Spacco; Hovemeyer; Bonner; Lefever; Garcia; Mount",
    "name_identifier": 0,
    "affiliation": null,
    "availability": "by request",
    "format": null,
    "programming_language": "Python",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2013,
    "number_of_semesters": 4,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": null,
    "data_processing": null,
    "population": "CS-1",
    "units_number": null,
    "task_number": "~110",
    "sample_size": "~430",
    "sample_demographics": null,
    "country": "USA",
    "educational_institution": "Duke",
    "data_standard": null,
    "learning_environment": "ITAP",
    "aggregation": "Yes",
    "aggregation_level": "Keystrokes",
    "related_publication_url": null,
    "related_publication": "@article{10.5555/2400161.2400167,\nauthor = {Hovemeyer, David and Spacco, Jaime},\ntitle = {CloudCoder: A Web-Based Programming Exercise System},\nyear = {2013},\nissue_date = {January 2013},\npublisher = {Consortium for Computing Sciences in Colleges},\naddress = {Evansville, IN, USA},\nvolume = {28},\nnumber = {3},\nissn = {1937-4771},\nabstract = {CloudCoder is a web-based programming exercise system designed for introductory programming courses. Using CloudCoder, instructors can assign practice problems to reinforce concepts and assess mastery of skills. Students access their assigned problems using a web browser. A typical problem asks the student to write a function or complete program to perform a simple task such as classifying input or performing a computation on input data. When the student submits her solution to a problem, the server tests her code against a series of test cases designed by the instructor and reports which tests executed correctly. CloudCoder is inspired by existing systems such as Codingbat, but is designed to be installed and used widely. As such, CloudCoder is open source (https://github.com/daveho/CloudCoder) and supports programming exercises in multiple languages (currently C, Java, and Python).},\njournal = {J. Comput. Sci. Coll.},\nmonth = {jan},\npages = {30},\nnumpages = {1}\n}",
    "rights": null,
    "description": "CloudCoder is an open source web-based programming exercise system (inspired by CodingBat). It is designed to make it easy for instructors of introductory programming courses to assign short exercises to students for skills development and assessment. Currently, exercises in C/C++, Java, Python, and Ruby are supported.",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=439",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Bier2010,\nauthor = {Bier, Norman},\nurl = {https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=439},\ntitle = {OLI Introductory Programming with Media},\npublisher = {DataShop},\nyear = {2010},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "OLI Introductory Programming with Media",
    "creator": "Bier, Norman",
    "given_name": "Norman",
    "family_name": "Bier",
    "name_identifier": 0,
    "affiliation": "Carnegie Mellon University",
    "availability": "By request",
    "format": 0,
    "programming_language": "Java",
    "data_collection_start_date": 2010,
    "data_collection_end_date": 2010,
    "publication_year": 2010,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": 0,
    "measurement_type": 0,
    "data_processing": 0,
    "population": "CS-0",
    "units_number": "~10.8k",
    "task_number": 0,
    "sample_size": 29,
    "sample_demographics": 0,
    "country": 0,
    "educational_institution": null,
    "data_standard": 0,
    "learning_environment": 0,
    "aggregation": 0,
    "aggregation_level": 0,
    "related_publication_url": 0,
    "related_publication": 0,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": null,
    "resource_url": "Not found",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "CloudCoder",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "By request",
    "format": null,
    "programming_language": "C",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": null,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": null,
    "data_processing": null,
    "population": "CS-1",
    "units_number": null,
    "task_number": 115,
    "sample_size": "~210",
    "sample_demographics": null,
    "country": null,
    "educational_institution": "York College",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "Keystrokes",
    "related_publication_url": null,
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "Mob Programming",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": null,
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2019,
    "number_of_semesters": null,
    "data_protection": "--",
    "data_type": "--",
    "measurement_type": null,
    "data_processing": null,
    "population": null,
    "units_number": "--",
    "task_number": "--",
    "sample_size": 87,
    "sample_demographics": null,
    "country": null,
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "--",
    "related_publication_url": "PI: Chas Murray",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "RedBlackTreeTutor",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": null,
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2014,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "--",
    "measurement_type": null,
    "data_processing": null,
    "population": "Data Structures and Algorithms",
    "units_number": "~52k",
    "task_number": 3,
    "sample_size": 46,
    "sample_demographics": null,
    "country": null,
    "educational_institution": "Lafayette College",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "--",
    "related_publication_url": "Xhakaj and Liew 2015",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": null,
    "resource_url": "Not found",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "TMC ",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": "Java",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": null,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": null,
    "data_processing": null,
    "population": "CS-1",
    "units_number": "--",
    "task_number": "100+",
    "sample_size": 150,
    "sample_demographics": null,
    "country": null,
    "educational_institution": "University of Helsinki",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "Keystrokes",
    "related_publication_url": "--",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1801",
    "resource_url_type": "URL",
    "bibtex_source": "@data{rivers2016,\nauthor = {Rivers, Kelly; Harpstead, Eric;  Koedinger, Ken},\nurl = {https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=1801},\ntitle = {KC Modeling for Programming},\npublisher = {DataShop},\nyear = {2016},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "KC Modeling for Programming",
    "creator": "Rivers, Kelly; Harpstead, Eric;  Koedinger, Ken",
    "given_name": "Kelly; Eric; Ken",
    "family_name": "Rivers; Harpstead; Koedinger",
    "name_identifier": null,
    "affiliation": "Carnegie Mellon University, Pittsburg, MA",
    "availability": "open (through signup on Datashop)",
    "format": "rtf",
    "programming_language": "Python",
    "data_collection_start_date": 2016,
    "data_collection_end_date": 2016,
    "publication_year": 2016,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "Step",
    "data_processing": "Step-by-step token analysis",
    "population": "CS-1",
    "units_number": "~18k",
    "task_number": 40,
    "sample_size": 89,
    "sample_demographics": "Students",
    "country": "USA",
    "educational_institution": "Carnegie Mellon University",
    "data_standard": "Custom",
    "learning_environment": "ITAP",
    "aggregation": "yes",
    "aggregation_level": "Submission",
    "related_publication_url": "Rivers et al. 2016",
    "related_publication": "@inproceedings{10.1145/2960310.2960333,\nauthor = {Rivers, Kelly and Harpstead, Erik and Koedinger, Ken},\ntitle = {Learning Curve Analysis for Programming: Which Concepts Do Students Struggle With?},\nyear = {2016},\nisbn = {9781450344494},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/2960310.2960333},\ndoi = {10.1145/2960310.2960333},\nabstract = {The recent surge in interest in using educational data mining on student written programs has led to discoveries about which compiler errors students encounter while they are learning how to program. However, less attention has been paid to the actual code that students produce. In this paper, we investigate programming data by using learning curve analysis to determine which programming elements students struggle with the most when learning in Python. Our analysis extends the traditional use of learning curve analysis to include less structured data, and also reveals new possibilities for when to teach students new programming concepts. One particular discovery is that while we find evidence of student learning in some cases (for example, in function definitions and comparisons), there are other programming elements which do not demonstrate typical learning. In those cases, we discuss how further changes to the model could affect both demonstrated learning and our understanding of the different concepts that students learn.},\nbooktitle = {Proceedings of the 2016 ACM Conference on International Computing Education Research},\npages = {143–151},\nnumpages = {9},\nkeywords = {educational data mining, learning curve analysis, knowledge components, programming syntax},\nlocation = {Melbourne, VIC, Australia},\nseries = {ICER '16}\n}",
    "rights": "https://pslcdatashop.web.cmu.edu/Terms",
    "description": "Step-by-step analysis of students solving introductory programming questions in Python",
    "research_question": "can\nwe successfully apply the methods of knowledge component\nmodeling and learning curve analysis to code-writing\nprogramming data, and can we use the resulting models to\nevaluate student learning? ",
    "future_work": "Design test items to target\nspecific KCs, then have the students complete these items after\npracticing, in order to see whether students perform better on\nitems that are shown as mastered in the model. ",
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=3427",
    "resource_url_type": "URL",
    "bibtex_source": "@data{iSnap15,\nurl = {https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=3427},\nauthor = {Cliff Shafer},\npublisher = {DataShop},\ntitle = {Fall 2019 use of OpenDSA Formal Languages eTextbook},\nyear = {2019},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Fall 2019 use of OpenDSA Formal Languages eTextbook",
    "creator": "Shaffer, Clifford A.",
    "given_name": "Clifford",
    "family_name": "Shaffer",
    "name_identifier": "https://orcid.org/0000-0003-0001-0295",
    "affiliation": "Virginia Tech",
    "availability": "open",
    "format": null,
    "programming_language": null,
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2019,
    "publication_year": 2019,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "eTextbook Log",
    "measurement_type": "--",
    "data_processing": null,
    "population": null,
    "units_number": "--",
    "task_number": "--",
    "sample_size": "--",
    "sample_demographics": "--",
    "country": "USA",
    "educational_institution": "Virginia Tech\n",
    "data_standard": "--",
    "learning_environment": "--",
    "aggregation": "--",
    "aggregation_level": "--",
    "related_publication_url": "https://dl.acm.org/doi/abs/10.1145/3408877.3432398",
    "related_publication": "@inproceedings{10.1145/3408877.3432398,\nauthor = {Mohammed, Mostafa and Shaffer, Clifford A. and Rodger, Susan H.},\ntitle = {Teaching Formal Languages with Visualizations and Auto-Graded Exercises},\nyear = {2021},\nisbn = {9781450380621},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3408877.3432398},\ndoi = {10.1145/3408877.3432398},\nabstract = {The material taught in a Formal Languages and Automata (FLA) course is mathematical in nature and requires students to practice proofs and algorithms to understand the content. Traditional FLA textbooks are heavy on prose, and homework typically consists of solving many paper exercises. Instructors often make use of Finite State Machine simulators like the JFLAP package. JFLAP allows students to interactively build models and apply different algorithms to these models, providing both a more interactive and a more visual approach. However, course materials have still traditionally relied largely on prose and hand-graded exercises, limiting both the interaction and the amount of practice. In this paper, we propose an eTextbook with integrated tools (simulators and auto-graded exercises) that allow for greater interactivity and levels of engagement. To evaluate the pedagogical effectiveness of our approach, we conducted performance evaluations across different offerings of an FLA course. Results indicate that students using the integrated eTextbook performed better than did a control group using a traditional textbook approach. Students gave positive feedback regarding the usefulness of the auto-graded exercises for practicing different FLA concepts.},\nbooktitle = {Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},\npages = {569–575},\nnumpages = {7},\nkeywords = {visualizations, formal languages, auto-graded exercises, OpenFLAP, OpenDSA, JFLAP},\nlocation = {Virtual Event, USA},\nseries = {SIGCSE '21}\n}\n\n",
    "rights": "no additional terms associated with this project.",
    "description": "Student utilization of e textbook, student perceptions and performance on exams",
    "research_question": "RQ1 What feedback do students give regarding their experience\nwith the various exercises?\nRQ2 How does performance on exams for the intervention group\ncompare to performance of the control group students on the same\nset of questions?",
    "future_work": "In future, we will focus on sections of the course that cover topics\nthat do not present easy opportunities for a visual presentation, or\ninteractive exercises. We will develop more PE for PDAs, and TMs.\nWe are investigating an approach based on the Programmed\nInstruction technique [31–33]. We believe that many aspects of a\nFLA course might benefit from a presentation based on Programmed\nInstruction since this can be made to be more interactive than the\ncurrent plain prose approach for those topics.",
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=4685",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Miller,\nurl = {https://pslcdatashop.web.cmu.edu/DatasetInfo?datasetId=4685},\nauthor = {Brad Miller},\npublisher = {DataShop},\ntitle = {Runestone Interactive},\nyear = {N/A},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Runestone Interactive",
    "creator": "Miller, Brad",
    "given_name": "Brad",
    "family_name": "Miller",
    "name_identifier": null,
    "affiliation": "Runestone Interactive",
    "availability": "By request",
    "format": "txt",
    "programming_language": null,
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2019,
    "publication_year": null,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "eTextbook Log",
    "measurement_type": "Response Time",
    "data_processing": "Number of Hints and Net Response time",
    "population": null,
    "units_number": "~5k",
    "task_number": null,
    "sample_size": 46,
    "sample_demographics": "Students ",
    "country": "USA",
    "educational_institution": "Runstone Academy",
    "data_standard": null,
    "learning_environment": "Runestone Interactive",
    "aggregation": "Yes",
    "aggregation_level": "Submission",
    "related_publication_url": "Brad Miller",
    "related_publication": null,
    "rights": "Acknowldgement",
    "description": "Analsysis of student hint seeking behaviour in relation to time spent",
    "research_question": "How do student hint seeking behaviours correlate to the time spent on solving a problem?",
    "future_work": "Possible Directions for Future Work include utilization of GenAI",
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/Project?id=315",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Bier,\nurl = {https://pslcdatashop.web.cmu.edu/Project?id=315},\nauthor = {Norman Bier},\npublisher = {DataShop},\ntitle = {OLI Principles of Computing},\nyear = {N/A},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "OLI Principles of Computing",
    "creator": "Bier, Norman",
    "given_name": "Norman",
    "family_name": "Bier",
    "name_identifier": null,
    "affiliation": "Carnegie Mellon University",
    "availability": "By request",
    "format": null,
    "programming_language": "Python",
    "data_collection_start_date": 2016,
    "data_collection_end_date": 2021,
    "publication_year": null,
    "number_of_semesters": 9,
    "data_protection": "Anonymized",
    "data_type": "--",
    "measurement_type": null,
    "data_processing": "Step-by-step problem solving",
    "population": "CS-0",
    "units_number": 375558,
    "task_number": null,
    "sample_size": "2.1k",
    "sample_demographics": "Students",
    "country": "USA",
    "educational_institution": "CMU, Santa Ana College",
    "data_standard": "--",
    "learning_environment": "Open Learning Initiative",
    "aggregation": "Yes",
    "aggregation_level": "Keystroke",
    "related_publication_url": "https://oli.cmu.edu/courses/principles-of-computation-with-python-open-free/",
    "related_publication": "@misc{Bier, title={Principles of computation with Python - Open & Free}, url={https://oli.cmu.edu/courses/principles-of-computation-with-python-open-free/}, journal={OLI}, author={Bier, Norman}} ",
    "rights": null,
    "description": "Python ",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "Python Trace Table Tutor",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": "Python",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2017,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "--",
    "measurement_type": null,
    "data_processing": null,
    "population": null,
    "units_number": "--",
    "task_number": "--",
    "sample_size": "~350",
    "sample_demographics": null,
    "country": null,
    "educational_institution": "UPitt",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "--",
    "related_publication_url": "Huang et al. 2022",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "QuizJET",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": "Java",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2014,
    "number_of_semesters": 11,
    "data_protection": "Anonymized",
    "data_type": "Quiz",
    "measurement_type": null,
    "data_processing": null,
    "population": "CS-1",
    "units_number": "--",
    "task_number": "--",
    "sample_size": "~500",
    "sample_demographics": null,
    "country": null,
    "educational_institution": "UPitt",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "Submission",
    "related_publication_url": "Hsiao et al. 2008",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "ReadingCircle",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": null,
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2016,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Quiz",
    "measurement_type": null,
    "data_processing": null,
    "population": "Graduate course on Informational Retrieval",
    "units_number": "~9k",
    "task_number": 89,
    "sample_size": 22,
    "sample_demographics": null,
    "country": null,
    "educational_institution": "UPitt",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "Attempts",
    "related_publication_url": "Thaker et al. 2020",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "Utrecht Python Datasets",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": "Python",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2020,
    "number_of_semesters": 2,
    "data_protection": "--",
    "data_type": "--",
    "measurement_type": null,
    "data_processing": null,
    "population": "Intro to Computational thinking",
    "units_number": "~20k",
    "task_number": "--",
    "sample_size": "~100",
    "sample_demographics": null,
    "country": null,
    "educational_institution": "Utrecht Univeristy",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "--",
    "related_publication_url": "PI: Sergey Sosnovsky",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "INFSCI OOP Studies",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": "Java",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2014,
    "number_of_semesters": 4,
    "data_protection": "--",
    "data_type": "Test",
    "measurement_type": null,
    "data_processing": null,
    "population": "INFSCI OOP",
    "units_number": "~70k",
    "task_number": "--",
    "sample_size": "~160",
    "sample_demographics": null,
    "country": null,
    "educational_institution": "UPitt",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "Grades",
    "related_publication_url": "PI: Peter Brusilovsky",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "Datashop@CMU",
    "resource_url_type": null,
    "bibtex_source": null,
    "title": "Australian Institute Python Datasets",
    "creator": null,
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": null,
    "availability": "Private",
    "format": null,
    "programming_language": "Python",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2020,
    "number_of_semesters": 4,
    "data_protection": "Anonymized",
    "data_type": "--",
    "measurement_type": null,
    "data_processing": null,
    "population": null,
    "units_number": "--",
    "task_number": "--",
    "sample_size": "~350",
    "sample_demographics": null,
    "country": null,
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "--",
    "related_publication_url": "PI: Aleksandra Klasnja-Milicevic",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": null
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DataShop",
    "resource_url": "https://pslcdatashop.web.cmu.edu/Project?id=377",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Koedinger_2015-2022,\nurl = {https://pslcdatashop.web.cmu.edu/Project?id=377},\nauthor = {Ken Koedinger},\npublisher = {DataShop},\ntitle = {E-Learning Design Course Instances},\nyear = {2022},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "E-learning Design Course Instances",
    "creator": "Koedinger, Ken",
    "given_name": "Ken ",
    "family_name": "Koedinger",
    "name_identifier": "https://orcid.org/0000-0002-5850-4768",
    "affiliation": "Carnegie Mellon University",
    "availability": "By request",
    "format": "txt",
    "programming_language": null,
    "data_collection_start_date": 2015,
    "data_collection_end_date": 2022,
    "publication_year": 2022,
    "number_of_semesters": 10,
    "data_protection": "Anonymized",
    "data_type": null,
    "measurement_type": null,
    "data_processing": 0,
    "population": null,
    "units_number": 0,
    "task_number": 0,
    "sample_size": "~230",
    "sample_demographics": 0,
    "country": "USA",
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": 0,
    "aggregation_level": 0,
    "related_publication_url": null,
    "related_publication": null,
    "rights": 0,
    "description": 0,
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Github",
    "resource_url": "https://github.com/adaptive-learning/robomission",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Effenberger_2018,\nurl = {https://github.com/adaptive-learning/robomission},\nauthor = {Tomáš Effenberger},\npublisher = {Github},\ntitle = {Robomission},\nyear = {2018},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "Robomission",
    "creator": "Adaptive Learning Group at Masaryk University",
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": "Masaryk University",
    "availability": "open",
    "format": "py",
    "programming_language": "Block-based programming",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": null,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": null,
    "data_processing": null,
    "population": null,
    "units_number": null,
    "task_number": 75,
    "sample_size": null,
    "sample_demographics": null,
    "country": "Czech Republic",
    "educational_institution": "Masaryk University",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": "Yes",
    "aggregation_level": "Snapshots",
    "related_publication_url": "https://doi.org/10.1145/3231644.3231670",
    "related_publication": "@inproceedings{10.1145/3231644.3231670,\nauthor = {Effenberger, Tom\\'{a}\\v{s} and Pel\\'{a}nek, Radek},\ntitle = {Towards making block-based programming activities adaptive},\nyear = {2018},\nisbn = {9781450358866},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3231644.3231670},\ndoi = {10.1145/3231644.3231670},\nabstract = {Block-based environments are today commonly used for introductory programming activities like those that are part of the Hour of Code campaign, which reaches millions of students. These activities typically consist of a static series of problems. Our aim is to make this type of activities more efficient by incorporating adaptive behavior. In this work, we discuss steps towards this goal, specifically a proposal and implementation of a programming game that supports both elementary problems and interesting programming challenges and thus provides an environment for meaningful adaptation. We also discuss methods of adaptivity and the issue of evaluating student performance while solving a problem.},\nbooktitle = {Proceedings of the Fifth Annual ACM Conference on Learning at Scale},\narticleno = {13},\nnumpages = {4},\nlocation = {London, United Kingdom},\nseries = {L@S '18}\n}",
    "rights": 0,
    "description": "Block-based environments are today commonly used for introductory programming activities like those that are part of the Hour of Code campaign, which reaches millions of students. These activities typically consist of a static series of problems. Our aim is to make this type of activities more efficient by incorporating adaptive behavior. In this work, we discuss steps towards this goal, specifically a proposal and implementation of a programming game that supports both elementary problems and interesting programming challenges and thus provides an environment for meaningful adaptation. We also discuss methods of adaptivity and the issue of evaluating student performance while solving a problem.",
    "research_question": 0,
    "future_work": 0,
    "fairness_score": "Total score: 27% (initial)\nFindability:  2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 0 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "CodeBench",
    "resource_url": "https://codebench.icomp.ufam.edu.br/dataset/",
    "resource_url_type": "URL",
    "bibtex_source": "@data{CodeBench_2016,\nurl = {https://codebench.icomp.ufam.edu.br/dataset/},\nauthor = {{Institute of Computing (IComp} of the Federal University of Amazonas},\npublisher = {CodeBench},\ntitle = {CodeBench},\nversion = {1.70},\nyear = {2023},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "CodeBench",
    "creator": "Institute of Computing (IComp} of the Federal University of Amazonas",
    "given_name": null,
    "family_name": null,
    "name_identifier": null,
    "affiliation": "Institute of Computing (IComp} of the Federal University of Amazonas",
    "availability": "open",
    "format": " data",
    "programming_language": null,
    "data_collection_start_date": 2016,
    "data_collection_end_date": 2023,
    "publication_year": 2023,
    "number_of_semesters": 16,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "log data",
    "data_processing": null,
    "population": "CS-1",
    "units_number": 0,
    "task_number": 16204,
    "sample_size": 4766,
    "sample_demographics": "Students",
    "country": "Brasil",
    "educational_institution": "IComp",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": "Yes",
    "aggregation_level": "All Snapshots",
    "related_publication_url": null,
    "related_publication": null,
    "rights": 0,
    "description": "CodeBench  is a Programming Online Judge developed by the Institute of Computing (IComp) of the Federal University of Amazonas, Brazil. Through Codebench, teachers can provide lists of programming exercises to their students, who in turn must develop solutions for each exercise through an embedded IDE. Once a student submits a source code for a given exercise, the system instantly notifies the student whether him/her  solution is correct or not. The CodeBench automatically logs all actions performed by students on embedded IDE during their attempts to solve the proposed exercises. This dataset contains all logs collected from CS1 students during 2016 to 2022.",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zenodo",
    "resource_url": "https://doi.org/10.5281/zenodo.5752559",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{wouter_groeneveld_2021_5752559,\nauthor       = {Wouter Groeneveld and\n                  Brett A. Becker and\n                  Joost Vennekens},\ntitle        = {{How Creatively Are We Teaching and Assessing \n                   Creativity in Computing Education: A Systematic\n                   Literature Review}},\nmonth        = dec,\nyear         = 2021,\npublisher    = {Zenodo},\nversion      = {1.0},\ndoi          = {10.5281/zenodo.5752559},\nurl          = {https://doi.org/10.5281/zenodo.5752559},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "How Creatively Are We Teaching and Assessing Creativity in Computing Education: A Systematic Literature Review",
    "creator": "Groeneveld, Wouter; Becker, Brett A.; Vennekens, Joost",
    "given_name": "Groeneveld; Becker; Vennekens",
    "family_name": "Wouter; Brett A.; Joost",
    "name_identifier": "https://orcid.org/0000-0001-5099-7177; https://orcid.org/0000-0003-1446-647X; https://orcid.org/0000-0002-0791-0176",
    "affiliation": "KU Leuven; University College Dublin; KU Leuven",
    "availability": "open",
    "format": "xlsx",
    "programming_language": null,
    "data_collection_start_date": 2020,
    "data_collection_end_date": 2021,
    "publication_year": 2021,
    "number_of_semesters": null,
    "data_protection": null,
    "data_type": "Literature Review",
    "measurement_type": "Literature Review",
    "data_processing": null,
    "population": null,
    "units_number": null,
    "task_number": null,
    "sample_size": null,
    "sample_demographics": null,
    "country": null,
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": "Wouter et al. 2023",
    "related_publication": "@inproceedings{10.1145/3478431.3499360,\nauthor = {Groeneveld, Wouter and Becker, Brett A. and Vennekens, Joost},\ntitle = {How Creatively Are We Teaching and Assessing Creativity in Computing Education: A Systematic Literature Review},\nyear = {2022},\nisbn = {9781450390705},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3478431.3499360},\ndoi = {10.1145/3478431.3499360},\nabstract = {Previous studies investigating and identifying non-technical skills of computing show that creative skills play an important role in tackling difficult programming problems. In the field of cognitive psychology, creativity has been extensively researched, and many of these methods can be adapted for application in computing education. We conducted a systematic literature review to support research on creativity in computing education by summarizing relevant theories, instruments, and other prior work. The review encompasses all SIGCSE venues and major journals in the field, providing a perspective of the current landscape on teaching and assessing creativity, in the context of computing in higher education. We identify which papers explore creativity as a central theoretical basis, revealing eight major themes. We also found seven commonly used measurement instruments. Creativity theories that are notably absent are also discussed, as are pedagogical implications of the approaches to fostering creativity in computing education. This paper serves to support the community by highlighting the interdisciplinary aspects of creativity research applicable in computing contexts. Additionally, it provides practical guidance and implications for educators in leveraging creativity in the classroom.},\nbooktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education - Volume 1},\npages = {934–940},\nnumpages = {7},\nkeywords = {creativity, programming, literature review, survey, assessment, cs1, problem solving, systematic review},\nlocation = {Providence, RI, USA},\nseries = {SIGCSE 2022}\n}",
    "rights": "Creative Commons Attribution 4.0 International",
    "description": null,
    "research_question": "systematic literature review to support research on creativity in \ncomputing education by summarizing relevant theories, instruments, and other prior work",
    "future_work": null,
    "fairness_score": "Total score: 66% (moderate)\nFindability: 6 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Apollo - University of Cambridge Repository",
    "resource_url": "https://doi.org/10.17863/CAM.87121",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{Sentance_2020,\ndoi = {10.17863/CAM.87121},\nauthor = {Sentance,  Sue and Tshukudu,  Ethel and Quille,  Keith},\nkeywords = {Botswana,  computing education,  computing teachers,  K-12 computing,  Kenya,  Nigeria,  Uganda},\ntitle = {METRECC Africa 2020 data},\npublisher = {Apollo - University of Cambridge Repository},\nyear = {2022},\ncopyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "METRECC Africa 2020 data",
    "creator": "Sentance,  Sue; Tshukudu,  Ethel; Quille,  Keith",
    "given_name": "Sue; Ethel; Keith",
    "family_name": "Sentance; Tshukudu; Quille",
    "name_identifier": "https://orcid.org/0000-0002-0259-7408 ; ; ",
    "affiliation": "University of Cambridge",
    "availability": "open",
    "format": "xls, txt, csv",
    "programming_language": null,
    "data_collection_start_date": 2020,
    "data_collection_end_date": 2021,
    "publication_year": 2022,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Survey Data",
    "measurement_type": "Survey",
    "data_processing": null,
    "population": "K-12",
    "units_number": 58,
    "task_number": null,
    "sample_size": 58,
    "sample_demographics": "Botswana; Kenya; Nigeria; Uganda",
    "country": "Botswana; Kenya; Nigeria; Uganda;",
    "educational_institution": null,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": "https://doi.org/10.1145/3554924",
    "related_publication": "@article{10.1145/3554924,\nauthor = {Tshukudu, Ethel and Sentance, Sue and Adelakun-Adeyemo, Oluwatoyin and Nyaringita, Brenda and Quille, Keith and Zhong, Ziling},\ntitle = {Investigating K-12 Computing Education in Four African Countries (Botswana, Kenya, Nigeria, and Uganda)},\nyear = {2023},\nissue_date = {March 2023},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nvolume = {23},\nnumber = {1},\nurl = {https://doi.org/10.1145/3554924},\ndoi = {10.1145/3554924},\nabstract = {Motivation. As K-12 computing education becomes more established throughout the world, there is an increasing focus on accessibility for all, whether in a particular country or setting or in areas of the world that may not yet have computing established. This is primarily articulated as an equity issue. The recently developed capacity for, access to, participation in, and experience of computer science education (CAPE) Framework is one way of demonstrating stages and dependencies and understanding relative equity, taking into consideration the disparities between sub-populations. While there is existing research that covers the state of computing education and equity issues, it is mostly in high-income countries; there is minimal research in the context of low-middle-income countries like the sub-Saharan African countries.Objectives. The objective of the article is therefore to report on a pilot study investigating the capacity (one of the equity issues), for delivering computing education in four sub-Saharan African countries: Botswana, Kenya, Nigeria and Uganda, countries that are in different geographic regions as well as in different income brackets (low-middle income).Method. In addition to reviewing the capacity issues of curriculum and policy around computing education in each country, we surveyed 58 teachers about the infrastructure, resources, professional development, and curriculum for computing in their country. We used a localized version of the MEasuring TeacheR Enacted Computing Curriculum (METRECC) instrument for this purpose.Results. We analyzed the results through the lens of the CAPE framework at the capacity level. We identified similarities and differences in the data from teachers who completed the original METRECC survey, all of whom were from high-income countries and African teachers. The data revealed statistically significant differences between the two datasets in relation to access to resources and professional development opportunities in computer studies/computer science, with the African teachers experiencing more barriers. Results further showed that African teachers focus less on teaching algorithms and programming than teachers from high-income countries. In addition, we found differences between African countries in the study, reflecting their relative access to IT infrastructure and resources.Discussion. The findings suggest that African countries are still struggling with the lowest level of the CAPE pyramid, Capacity for as compared to high-income countries. This level is concerned with the availability of resources that support the enactment of a computing curriculum of high quality. The CAPE framework helps map the progression from Capacity for to Experience of computer science education as a route to equity, but to support development in low and middle-income countries, it may be helpful to have the capacity level finely grained. Such an adaptation draws out dependencies between policy and vision, infrastructure, curriculum implementation, and teacher professional development. More research is recommended to investigate these dependencies further and thus support and facilitate the development of global computing education.},\njournal = {ACM Trans. Comput. Educ.},\nmonth = {jan},\narticleno = {9},\nnumpages = {29},\nkeywords = {Curriculum, teacher education, professional development, K-12 computing education, Africa}\n}",
    "rights": "CC BY-NC-SA (Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International)",
    "description": "This file includes the responses from the 58 study participants to the survey questions on demographics, years of teaching experience, qualifications, classroom time, topics covered in computer science teaching, capacity in terms of support and resources available and barriers experienced for professional development",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 87% (advanced)\nFindability: 7 of 7\nAccessibility: 2 of 3\nInteroperability: 4 of 4\nReusability: 8 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "FalconCode",
    "resource_url": "https://falconcode.dfcs-cloud.net/index.php",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Falconcode_2023,\nurl = {https://falconcode.dfcs-cloud.net/request.php},\nauthor = {de Freitas, Adrian and Coffman, Joel and de Freitas, Michelle and Wilson, Justin and Weingart, Troy},\ntitle = {FalconCode},\nyear = {2023},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "FalconCode",
    "creator": "Adrian de Freitas; Joel Coffman;Michelle de Freitas;Justin Wilson; Troy Weingart",
    "given_name": "Adrian; Joel: Michelle; Justin; Troy",
    "family_name": "de Freitas; Coffan; de Freitas; Wilson; Weingart",
    "name_identifier": 0,
    "affiliation": "United States Air Force Academy\n",
    "availability": "By request",
    "format": 0,
    "programming_language": "Python",
    "data_collection_start_date": 0,
    "data_collection_end_date": 0,
    "publication_year": 2022,
    "number_of_semesters": 5,
    "data_protection": "anonymizes",
    "data_type": "students code",
    "measurement_type": "programming assignments including homework and exam questions",
    "data_processing": "1)collect code samples from students, 2)remove PII,and3)insert meta data tags.",
    "population": "CS1 students",
    "units_number": 0,
    "task_number": 0,
    "sample_size": 2000,
    "sample_demographics": "Undergrads across multiple disciplines",
    "country": "USA",
    "educational_institution": "United States Air Force Academy",
    "data_standard": 0,
    "learning_environment": "A python dev environment with custom PythonPackage Index(PyPI) ",
    "aggregation": "yes",
    "aggregation_level": "code snapshots",
    "related_publication_url": "Freitas 2023",
    "related_publication": "@inproceedings{10.1145/3545945.3569822,\nauthor = {de Freitas, Adrian and Coffman, Joel and de Freitas, Michelle and Wilson, Justin and Weingart, Troy},\ntitle = {FalconCode: A Multiyear Dataset of Python Code Samples from an Introductory Computer Science Course},\nyear = {2023},\nisbn = {9781450394314},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3545945.3569822},\ndoi = {10.1145/3545945.3569822},\nabstract = {The lack of large and diverse datasets of student code samples limits some forms of computer science education research. To address this problem, we created FalconCode, a novel collection of over 1.5 million Python programs from over two thousand undergraduate students at the United States Air Force Academy. FalconCode captures over five semesters worth of code samples from our introduction to computing course, which is taken by every student regardless of their academic major. The dataset contains student code submissions for over 800 programming assignments, as well as additional metadata such as the prompt for each assignment, the testcase(s) used to evaluate student submissions, and the specific skills needed to solve each problem. In this paper, we describe the methodology used to create FalconCode and the steps taken to anonymize the data. We then describe FalconCode's data schema, and show how it can support a wide range of research---including those utilizing machine learning (ML) and artificial intelligence (AI). FalconCode is provided free-of-charge, and is available upon request for computer science education research.},\nbooktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},\npages = {938–944},\nnumpages = {7},\nkeywords = {computer science education, dataset, student code repository},\nlocation = {Toronto ON, Canada},\nseries = {SIGCSE 2023}\n}",
    "rights": null,
    "description": "FalconCode -a collection of over 1.5 million Python programs from over two thousand undergraduate students capturesoverfivesemestersworthofcodesamplesfromourintroductiontocomputingcourse,whichistakenbyeverystudent regardlessof theiracademicmajor.",
    "research_question": "gather frequent snapshots of student CS1 codes, anonymize it and add it to dataset to be reused by other researchers",
    "future_work": "further enhance data processing pipeline to generate even more metadata for each student submission. Collect programs written in languages such as C and C#,which are used in subsequent programming courses",
    "fairness_score": "Total score: 4% (initial)\nFindability: 1 of 7\nAccessibility: 0 of 3\nInteroperability: 0 of 4\nReusability: 0 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zenodo",
    "resource_url": "https://doi.org/10.5281/zenodo.6903968",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{leinonen_2022_6903968,\nauthor       = {Leinonen, Juho and\n                  Hellas, Arto},\ntitle        = {IDE Action Log Dataset from a CS1 MOOC},\nmonth        = jul,\nyear         = 2022,\npublisher    = {Zenodo},\ndoi          = {10.5281/zenodo.6903968},\nurl          = {https://doi.org/10.5281/zenodo.6903968},\nnote = {Last Access: 5 February, 2024},\n}",
    "title": "IDE Action Log Dataset from a CS1 MOOC",
    "creator": "Leinonen, Juho;\nHellas, Arto",
    "given_name": "Juho; Arto",
    "family_name": "Leinonen; Hellas",
    "name_identifier": "https://orcid.org/0000-0001-6829-9449 https://orcid.org/0000-0001-6502-209X",
    "affiliation": "University of Helsinki\n; Aalto University",
    "availability": "open",
    "format": "csv",
    "programming_language": "Java",
    "data_collection_start_date": 2017,
    "data_collection_end_date": 2017,
    "publication_year": 2017,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "log data",
    "measurement_type": "programming exercise",
    "data_processing": "data only contains medata and not student code",
    "population": "MOOC on (CS1)",
    "units_number": 1048575,
    "task_number": 6,
    "sample_size": 473,
    "sample_demographics": "novice CS students",
    "country": "Finland",
    "educational_institution": "University of Helsinki",
    "data_standard": 0,
    "learning_environment": "IDE with custom plugin (Test my Code)",
    "aggregation": "yes",
    "aggregation_level": "Keystrokes and IDE events (run code, submit exercise, etc.)",
    "related_publication_url": "Leinonen",
    "related_publication": "@proceedings{leinonen_2022_6983459,\n  title        = {Open IDE Action Log Dataset from a CS1 MOOC},\n  year         = 2022,\n  publisher    = {Zenodo},\n  month        = aug,\n  doi          = {10.5281/zenodo.6983459},\n  url          = {https://doi.org/10.5281/zenodo.6983459}\n}",
    "rights": "CC 4.0",
    "description": "This is a a dataset containing Integrated Development Environment (IDE) logs from an introductory programming MOOC. The dataset contains information on when actions in the IDE were performed in relation to deadlines over the different parts of the course. One exceptional aspect of the dataset is that part of the logs have been gathered at the keystroke level, allowing for fine-grained insight into the learning process. In addition to the IDE logs themselves, the dataset has information on whether students included in the data passed the course. This can facilitate further research that analyzes how time-related behavior relates to performance in introductory programming courses.",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 66% (moderate)\nFindability: 6 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Mendeley Data",
    "resource_url": "https://doi.org/10.17632/43m7g42bcp.3",
    "resource_url_type": "DOI ",
    "bibtex_source": "@data{Campbell_2022,\ndoi = {10.17632/43m7g42bcp.3},\nurl = {https://doi.org/10.17632/43m7g42bcp.3},\nauthor = {Oladele Campbell;\nHarrison Atagana},\npublisher = {Mendeley Data},\ntitle = {The Conventional versus a constructionist-Scratch programming instructions and students achievements in higher education CS1 classes},\nyear = {2022},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "The Conventional versus a constructionist-Scratch programming instructions and students achievements in higher education CS1 classes.",
    "creator": "Campbell, Oladele; Atagana, Harrison",
    "given_name": "Oladele; Harrison",
    "family_name": "Campbell; Atagana",
    "name_identifier": "https://orcid.org/0000-0003-4922-6791  https://orcid.org/0000-0002-7077-9967",
    "affiliation": "Niger State Polytechnic, University of South Africa, Federal Polytechnic Nasarawa, Federal Polytechnic Bida\n",
    "availability": "open",
    "format": "xlsx",
    "programming_language": "Scratch, VB",
    "data_collection_start_date": 0,
    "data_collection_end_date": 0,
    "publication_year": 2022,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Computational thinking, Conceptual and programming open-ended short answers. ",
    "measurement_type": " a student profile questionnaire, a pretest, and posttest",
    "data_processing": "for analysis, a Coarsened Exact Matching (CEM) algorithm to generate matched samples of experimental and control data was used",
    "population": "CS1",
    "units_number": 82,
    "task_number": "Computational thinking/programming",
    "sample_size": 520,
    "sample_demographics": "novice computer science students/ novice programmers",
    "country": "Nigeria",
    "educational_institution": "4 colleges",
    "data_standard": null,
    "learning_environment": "scratch",
    "aggregation": "yes",
    "aggregation_level": "pre and post test",
    "related_publication_url": "Campbell",
    "related_publication": "@article{campbell2022search,\n  title={In search of experimental evidence on Scratch programming and students’ achievements in the first-year college computing class? Consider these datasets},\n  author={Campbell, Oladele O and Atagana, Harrison I},\n  journal={Data in Brief},\n  volume={45},\n  pages={108635},\n  year={2022},\n  publisher={Elsevier}\n}",
    "rights": null,
    "description": null,
    "research_question": "Is there any difference in the mean post-test achievement between CS1 students in the constructionist Scratch class and those in the conventional lecture-based class? other ",
    "future_work": null,
    "fairness_score": "Total score: 62% (moderate)\nFindability: 6 of 7\nAccessibility: 1 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DZHW",
    "resource_url": "https://metadata.fdz.dzhw.eu/en/data-packages/stu-studentsteps?page=1&size=10&type=surveys&version=1.0.0",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{kiesler2022data,\n         author = {Natalie Kiesler}, \n         title = {Dataset: Recursive problem solving in the online learning environment CodingBat by computer science students}, \n         howpublished = {Online}, \n         month = {June}, \n         year = {2022}, \n         note = {Datenerhebung: 2017. Version: 1.0.0. Datenpaketzugangsweg: Download-SUF. Hannover: FDZ-DZHW. Datenkuratierung: İkiz-Akıncı, Dilek. Last Access: 5 February, 2024},\n         url = {https://doi.org/10.21249/DZHW:studentsteps:1.0.0},\n         doi = {10.21249/DZHW:studentsteps:1.0.0}, \n}",
    "title": "Dataset: Recursive problem solving in the online learning environment CodingBat by computer science students",
    "creator": " Kiesler, Natalie",
    "given_name": "Natalie",
    "family_name": "Kiesler",
    "name_identifier": "https://orcid.org/0000-0002-6843-2729",
    "affiliation": "DIPF Leibniz Institute for Research and Information in Education",
    "availability": "open",
    "format": ".xlsx",
    "programming_language": "Java",
    "data_collection_start_date": 2017,
    "data_collection_end_date": 2017,
    "publication_year": 2017,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "screencast recording and transcription",
    "data_processing": "tokenization",
    "population": "CS1",
    "units_number": "--",
    "task_number": "2 tasks: factorial of n, Fibonacci sequence",
    "sample_size": 16,
    "sample_demographics": "novice programmers",
    "country": "Germany",
    "educational_institution": "University of Applied Sciences Fulde",
    "data_standard": null,
    "learning_environment": "CodingBat",
    "aggregation": "Yes",
    "aggregation_level": "Token level progress of students",
    "related_publication_url": "Kiesler 2022",
    "related_publication": "@phdthesis{kiesler2022diss,\n\ttitle = {{Kompetenzförderung in der Programmierausbildung durch Modellierung von Kompetenzen und informativem Feedback}},\n\tauthor = {Kiesler, Natalie},\n\tyear = {2022},\n\ttype = {Dissertation},\n\tschool = {{Johann Wolfgang Goethe-Universität}},\n\taddress = {Frankfurt am Main},\n\tnote = {Fachbereich Informatik und Mathematik},\n\tmonth = {Januar},\n}",
    "rights": "DZHW",
    "description": null,
    "research_question": "How does informative feedback during the use of (online) self-learning tools with programming exercises affect students? How do students use feedback options and hints in online learning environments?",
    "future_work": "The dataset can be used to evaluate and compare online learning environments with programming exercises for which feedback is offered (if these learning environments offer identical tasks).\nMoreover, feedback from experts could be compared with system feedback.  Such findings can be incorporated into teaching and the development of learning systems.",
    "fairness_score": "Total score: 62% (moderate)\nFindability: 6 of 7\nAccessibility: 1 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "GitHub",
    "resource_url": "https://github.com/Programming-Steps-Working-Group-2022/public-datasets",
    "resource_url_type": "URL",
    "bibtex_source": "@data{FiTech2022data,\nurl = {https://github.com/Programming-Steps-Working-Group-2022/public-datasets},\nauthor = {Jeuring et al.},\npublisher = {GitHub},\ntitle = {Programming-Steps-Working-Group-2022},\nyear = {2022},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Programming steps working group at ITiCSE'22",
    "creator": "Jeuring, Johan; Keuning, Hieke; Marwan, Samiha; Bouvier, Dennis; Izu, Cruz; Kiesler, Natalie; Lehtinen, Teemu; Lohr, Dominic; Peterson, Andrew; Sarsa, Sami",
    "given_name": "Johan; Hieke; Samiha; Dennis; Cruz; Natalie;  Teemu; Dominic; Andrew; Sami",
    "family_name": "Jeuring; Keuning; Marwan; Bouvier; Izu; Kiesler;  Lehtinen; Lohr; Peterson; Sarsa",
    "name_identifier": 0,
    "affiliation": "Utrecht University, Utrecht, Netherlands; University of Virginia, Raleigh, NC, USA; Southern Illinois University, Edwardsville, IL, USA; The University of Adelaide, Adelaide, Australia; DIPF Leibniz Institute for Research, Frankfurt, Germany; Aalto University, Aalto, Finland; Friedrich-Alexander-Universität, Erlangen-Nürnberg, Germany; University of Toronto Mississauga, Mississauga, Canada",
    "availability": "open",
    "format": "csv",
    "programming_language": "Dart",
    "data_collection_start_date": 0,
    "data_collection_end_date": 0,
    "publication_year": 2022,
    "number_of_semesters": 1,
    "data_protection": "Anonymized",
    "data_type": "Programming",
    "measurement_type": "keystroke and other log data from IDE",
    "data_processing": "tokenization",
    "population": "CS1",
    "units_number": 3604,
    "task_number": 2,
    "sample_size": 25,
    "sample_demographics": "novice CS students",
    "country": "Finland",
    "educational_institution": "Aalto University",
    "data_standard": 0,
    "learning_environment": "online IDE",
    "aggregation": "yes",
    "aggregation_level": "Keystroke",
    "related_publication_url": "Jeuring 2022",
    "related_publication": "@inproceedings{10.1145/3571785.3574124,\nauthor = {Jeuring, Johan and Keuning, Hieke and Marwan, Samiha and Bouvier, Dennis and Izu, Cruz and Kiesler, Natalie and Lehtinen, Teemu and Lohr, Dominic and Peterson, Andrew and Sarsa, Sami},\ntitle = {Towards Giving Timely Formative Feedback and Hints to Novice Programmers},\nyear = {2022},\nisbn = {9798400700101},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3571785.3574124},\ndoi = {10.1145/3571785.3574124},\nbooktitle = {Proceedings of the 2022 Working Group Reports on Innovation and Technology in Computer Science Education},\npages = {95–115},\nnumpages = {21},\nkeywords = {sequences of programming steps, learning programming, learning environments, feedback and hints, automated feedback},\nlocation = {<conf-loc>, <city>Dublin</city>, <country>Ireland</country>, </conf-loc>},\nseries = {ITiCSE-WGR '22}\n}",
    "rights": "CC 4.0",
    "description": "The data is from an online introductory programming course using Dart language.\nThe students have varied backgrounds and study from distance. The course is\navailable at https://fitech101.aalto.fi/fitech101/introduction-to-programming/ \nin Finnish. For the same reason the programs in this data are likely to include\ne.g. variable and function names in Finnish.\n\nThe published data includes\n* 2 assignments, see TaskDescription-A*.txt\n* 5 students in A79 assignment\n* 20 students in A81 assignment",
    "research_question": "1. How to annotate datasets consisting of steps students take towards solving a programming task within formation about when and how to give feedback and hints? 2. How does expert feedback relate to the feedback found in learning environments for programming?",
    "future_work": "An important contribution of this working group is that we found that there is still much work to be done to determine what kind of feedback to give, how to assess the feedback given by learning environments, and ultimately how to improve these environments. There are several directions for future work. First, since we think the expert-annotated datasets are a very useful resource, we encourage researchers to annotate more data. Second, we want to use the expert-annotated datasets to generalize how experts give feedback and hints on steps students take when working on programming tasks. These insights will be used to describe the design of a system giving automated feedback on student steps. Third, we also want to annotate steps students take when working on slightly larger tasks. Since possibilities to go off track are larger here, we need to think of a method to deal with this, probably involving connecting student steps to subgoals of a task. Fourth, we want to study what kind of feedback students expect at the various steps they take, and how this compares against the feedback specified by experts",
    "fairness_score": "Total score: 27% (initial)\nFindability: 2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 0 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "GitLab",
    "resource_url": "https://gitlab.com/iahmed4/concept-map-datasets-for-cybersecurity-courses",
    "resource_url_type": "URL",
    "bibtex_source": "@data{ahmed_2019,\nurl = {https://gitlab.com/iahmed4/concept-map-datasets-for-cybersecurity-courses},\nauthor = {Irfan Ahmed},\npublisher = {GitLab},\ntitle = {Concept Map for Cybersecurity Courses},\nyear = {2019},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Concept Map for Cybersecurity Courses",
    "creator": "Deshpande, Pranita; Ahmed, Irfan",
    "given_name": "Pranita; Irfan",
    "family_name": "Deshpande; Ahmed",
    "name_identifier": 0,
    "affiliation": "University of New Orleans; Virginia Commonwealth University",
    "availability": "open",
    "format": null,
    "programming_language": null,
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2019,
    "number_of_semesters": 1,
    "data_protection": null,
    "data_type": "Concept Map",
    "measurement_type": null,
    "data_processing": null,
    "population": "Cybersecurity",
    "units_number": "--",
    "task_number": "--",
    "sample_size": "--",
    "sample_demographics": null,
    "country": null,
    "educational_institution": "--",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": "--",
    "related_publication_url": "Despande 2019",
    "related_publication": null,
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 35% (initial)\nFindability: 2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 2 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zenodo",
    "resource_url": "https://zenodo.org/record/3506640#.ZF0WruzML0MZenodo",
    "resource_url_type": "DOI ",
    "bibtex_source": "@data{svabensky_2019_3506640,\nauthor       = {Švábenský, Valdemar and\n                  Vykopal, Jan and\n                  Čeleda, Pavel},\ntitle        = {{Dataset: What Are Cybersecurity Education Papers \n                   About? A Systematic Literature Review of SIGCSE\n                   and ITiCSE Conferences}},\nmonth        = oct,\nyear         = 2019,\npublisher    = {Zenodo},\ndoi          = {10.5281/zenodo.3506640},\nurl          = {https://doi.org/10.5281/zenodo.3506640},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Cybersecurity Literature Review",
    "creator": "Švábenský, Valdemar; Vykopal, Jan; Čeleda, Pavel",
    "given_name": "Valdemar; Jan; Pavel",
    "family_name": "Švábenský; Vykopal; Čeleda",
    "name_identifier": "https://orcid.org/0000-0001-8546-280X https://orcid.org/0000-0002-3425-0951 https://orcid.org/0000-0002-3338-2856",
    "affiliation": "Masaryk University",
    "availability": "open",
    "format": "xlsx, csv",
    "programming_language": null,
    "data_collection_start_date": 2010,
    "data_collection_end_date": 2019,
    "publication_year": 2019,
    "number_of_semesters": 0,
    "data_protection": 0,
    "data_type": "Literature Review",
    "measurement_type": "survey",
    "data_processing": null,
    "population": "Cybersecurity",
    "units_number": 90,
    "task_number": 9,
    "sample_size": 71,
    "sample_demographics": "universiites offering cyberseurity courses",
    "country": "USA",
    "educational_institution": "SIGCSE and iTiCSE",
    "data_standard": 0,
    "learning_environment": null,
    "aggregation": 0,
    "aggregation_level": 0,
    "related_publication_url": "Švábenský 2020",
    "related_publication": "@inproceedings{Svabensky2020what,\n    author    = {\\v{S}v\\'{a}bensk\\'{y}, Valdemar and Vykopal, Jan and \\v{C}eleda, Pavel},\n    title     = {{What Are Cybersecurity Education Papers About? A Systematic Literature Review of SIGCSE and ITiCSE Conferences}},\n    booktitle = {Proceedings of the 51st ACM Technical Symposium on Computer Science Education},\n    series    = {SIGCSE '20},\n    location  = {Portland, OR, USA},\n    publisher = {Association for Computing Machinery},\n    address   = {New York, NY, USA},\n    month     = {03},\n    year      = {2020},\n    pages     = {2--8},\n    numpages  = {7},\n    isbn      = {978-1-4503-6793-6},\n    url       = {https://doi.org/10.1145/3328778.3366816},\n    doi       = {10.1145/3328778.3366816},\n}",
    "rights": null,
    "description": "This paper discusses trends,and implications for further research in cybersecurity education.",
    "research_question": "Lack of education datasets available for cybersecurity education",
    "future_work": null,
    "fairness_score": "Total score: 35% (initial)\nFindability: 2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 2 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zenodo",
    "resource_url": "https://doi.org/10.5281/zenodo.4310241",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{abad_2020_4310241,\nauthor = {Abad, Cristina L and Ortiz-Holguin, Eduardo and Boza, Edwin F},\ndoi = {10.5281/zenodo.4310241},\nmonth = {dec},\npublisher = {Zenodo},\ntitle = {{SIGCSE-2021-DistributedSystemsSyllabiDataset}},\nurl = {https://doi.org/10.5281/zenodo.4310241},\nyear = {2020},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Distributed System Syllabi",
    "creator": "Abad, Cristina L;  \nOrtiz-Holguin, Eduardo;   \nBoza, Edwin;",
    "given_name": "Cristina; Eduardo; Edwin",
    "family_name": "Abad;  \nOrtiz-Holguin; Boza",
    "name_identifier": "https://orcid.org/0000-0002-9263-673X https://orcid.org/0000-0002-2347-4159",
    "affiliation": "Escuela Superior Politecnica del Litoral, ESPOL",
    "availability": "open",
    "format": "csv",
    "programming_language": null,
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2020,
    "publication_year": 2020,
    "number_of_semesters": null,
    "data_protection": "not anonymized",
    "data_type": "Syllabi",
    "measurement_type": "document analysis?",
    "data_processing": "no",
    "population": "Distributed Systems",
    "units_number": 52,
    "task_number": 13,
    "sample_size": 50,
    "sample_demographics": "universities offering distributed computing course",
    "country": "USA",
    "educational_institution": "Multiple universities",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": "no",
    "aggregation_level": 0,
    "related_publication_url": "Abad et al 2020",
    "related_publication": "@inproceedings{10.1145/3447545.3451197,author = {Abad, Cristina L. and Iosup, Alexandru and Boza, Edwin F. and Ortiz Holguin, Eduardo},\ntitle = {An Analysis of Distributed Systems Syllabi With a Focus on Performance-Related Topics},\nyear = {2021},\nisbn = {9781450383318},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3447545.3451197},\ndoi = {10.1145/3447545.3451197},\nbooktitle = {Companion of the ACM/SPEC International Conference on Performance Engineering},\npages = {121–126},\nnumpages = {6},\nkeywords = {curricula, course topics, syllabi, distributed systems},\nlocation = {Virtual Event, France},\nseries = {ICPE '21}\n}",
    "rights": "CC 4.0",
    "description": "authors try to map 51 offerings of distributed systems courses from different schools to two popular curriculum initiatives",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 66% (moderate)\nFindability: 6 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zenodo",
    "resource_url": "https://doi.org/10.5281/zenodo.5749825",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{anastasiia_birillo_2021_5749825,\nauthor = {Birillo, Anastasiia and Vlasov, Ilya and Burylov, Artyom and Selishchev, Vitalii and Goncharov, Artyom and Tikhomirova, Elena and Vyahhi, Nikolay and Bryksin, Timofey},\ndoi = {10.5281/zenodo.5749825},\nmonth = {dec},\npublisher = {Zenodo},\ntitle = {{Supplementary materials for the paper \"Hyperstyle : A Tool for Assessing the Code Quality of Solutions to Programming Assignments\"}},\nurl = {https://doi.org/10.5281/zenodo.5749825},\nyear = {2021},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Supplementary \nmaterials for the paper \"Hyperstyle : A Tool for Assessing the Code \nQuality of Solutions to Programming Assignments\"",
    "creator": "Birillo, Anastasiia; Vlasov, Ilya; Burylov, Artyom; Selishchev, Vitalii; Goncharov, Artyom; Tikhomirova, Elena; Vyahhi, Nikolay; Bryksin, Timofey",
    "given_name": "Anastasiia; Ilya; Artyom; Vitalii; Artyom; Elena; Nikolay; Timofey",
    "family_name": "Birillo; Vlasov; Burylov; Selishchev; Goncharov; Tikhomirova; Vyahhi; Bryksin",
    "name_identifier": 0,
    "affiliation": "1. JetBrains Research\n2. Saint Petersburg State University\n3. Stepik; Miro\n4. Higher School of Economics\n5. Computer Science Center\n6. Stepik\n7. JetBrains Research; Saint Petersburg State University",
    "availability": "open",
    "format": "csv",
    "programming_language": "Java and Python",
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2021,
    "publication_year": 2022,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": "Code Quality Issues",
    "measurement_type": "code snippet",
    "data_processing": "given a programming code, it generates feedback to improve code quality",
    "population": "programming tudents ",
    "units_number": 11886,
    "task_number": 7,
    "sample_size": 300,
    "sample_demographics": 0,
    "country": "Russia",
    "educational_institution": "St Petersburg State University, Russia",
    "data_standard": 0,
    "learning_environment": "JetBrains, Stepik",
    "aggregation": "yes",
    "aggregation_level": "student submission before and after using their tool Hyperstyle",
    "related_publication_url": "Birillo 2022",
    "related_publication": "@inproceedings{10.1145/3478431.3499294,\nauthor = {Birillo, Anastasiia and Vlasov, Ilya and Burylov, Artyom and Selishchev, Vitalii and Goncharov, Artyom and Tikhomirova, Elena and Vyahhi, Nikolay and Bryksin, Timofey},\ntitle = {Hyperstyle: A Tool for Assessing the Code Quality of Solutions to Programming Assignments},\nyear = {2022},\nisbn = {9781450390705},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3478431.3499294},\ndoi = {10.1145/3478431.3499294},\nbooktitle = {Proceedings of the 53rd ACM Technical Symposium on Computer Science Education - Volume 1},\npages = {307–313},\nnumpages = {7},\nkeywords = {refactoring, programming education, learning programming, code quality assessment, code formatting},\nlocation = {Providence, RI, USA},\nseries = {SIGCSE 2022}\n}",
    "rights": null,
    "description": null,
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 66% (moderate)\nFindability: 6 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "DZHW",
    "resource_url": "https://doi.org/10.21249/DZHW:dipit2020:1.0.0",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{Schulz2023Group,\nauthor = {Schulz, Sandra and Berndt, Sarah and Hawlitschek, Anja},\ndoi = {10.21249/DZHW:dipit2020:1.0.0},\nurl = {https://doi.org/10.21249/DZHW:dipit2020:1.0.0},\neditor = {{\\.I}kiz-Ak\\i{}nc\\i{}, Dilek and Niebuhr, Johanna},\nyear = {2023},\naddress = {Hanover},\ninstitution = {FDZ-DZHW},\ntitle = {Group work in {Learning} {Programming} ({GAPL}). {Data} {Collection}: 2020. {Version}: 1.0.0. {Data} {Package} {Access} {Way}: SUF: Download},\nnote = {Last Access: 5 February, 2024}, \n}",
    "title": "Group Work in Learning Programming",
    "creator": "\nSchulz, Sandra; \nBerndt, Sarah; \nHawlitschek, Anja;",
    "given_name": "Sandra; Sarah; Anja",
    "family_name": "Schulz; Berndt; Hawlitschek",
    "name_identifier": "https://orcid.org/0000-0002-2254-6579",
    "affiliation": "Humboldt-Universität zu Berlin; \nOtto-von-Guericke Universität Magdeburg",
    "availability": "restricted",
    "format": "docx",
    "programming_language": null,
    "data_collection_start_date": 2020,
    "data_collection_end_date": 2020,
    "publication_year": 2023,
    "number_of_semesters": null,
    "data_protection": "Anonymized",
    "data_type": null,
    "measurement_type": "Semi-structured Interviews",
    "data_processing": null,
    "population": "Lecturers, students",
    "units_number": null,
    "task_number": null,
    "sample_size": 25,
    "sample_demographics": "Germany",
    "country": "Germany",
    "educational_institution": "TU Bergakademie Freiberg, Otto-von-Guericke-Universität Magdeburg und Humboldt-Universität zu Berlin",
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": null,
    "related_publication": "@article{doi:10.1080/08993408.2021.2022361,\nauthor = {Sandra Schulz, Sarah Berndt and Anja Hawlitschek},\ntitle = {Exploring students’ and lecturers’ views on collaboration and cooperation in computer science courses - a qualitative analysis},\njournal = {Computer Science Education},\nvolume = {33},\nnumber = {3},\npages = {318-341},\nyear = {2023},\npublisher = {Routledge},\ndoi = {10.1080/08993408.2021.2022361},\nURL = { https://doi.org/10.1080/08993408.2021.2022361},\neprint = {https://doi.org/10.1080/08993408.2021.2022361}\n}",
    "rights": "Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Germany (CC BY-NC-SA 3.0)",
    "description": "The research project \"Digital Programming in Teams\" (DiP-iT) investigates how collaborative learning in computer science studies can be didactically developed and supported with digital tools. The project focuses on the use and implementation of learning analytics methods. The DiP-iT project aims to develop didactic and technical support in computer science studies for learning to program in teams. In order to achieve this goal, the sub-study \"Gruppenarbeit beim Programmieren lernen\" (GAPL; engl: Group work in Learning Programming)  first took stock of the initial situation at the three locations of the joint universities (TU Bergakademie Freiberg, Otto-von-Guericke University Magdeburg and Humboldt University Berlin). Interviews with lecturers (data set 1) and students (data set 2) of the three participating universities were conducted to determine the initial situation. It was analyzed to what extent cooperative and collaborative methods are already used in teaching to learn programming. Subsequently, it can be deduced, among other things, how collaborative programming learning can be supported in the future (technically, didactically, organizationally,\n etc.), where unused potentials lie and which obstacles must be considered in an implementation. \n\nThe lecturers hold basic courses on learning to program in computer science and were asked, for example, about the extent to which they use group work in their courses and what opportunities and risks they see in group work. The students of computer science have already participated in basic courses on learning to program in computer science or are participating in them in the semester of the interview. Among other things, they were asked about the extent to which they used group work in the course, how they experienced group work, and what opportunities and risks they see in group work.",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 47% (initial)\nFindability: 6 of 7\nAccessibility: 1.5 of 3\nInteroperability: 1 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "OSF",
    "resource_url": "https://doi.org/10.17605/OSF.IO/8QNDG",
    "resource_url_type": "DOI",
    "bibtex_source": " @data{Schmellenkamp_2022,\n  title={Discovering and quantifying misconceptions in formal methods using intelligent tutoring systems},\n  url={https://osf.io/8qndg/},\n  DOI={10.17605/OSF.IO/8QNDG},\n  publisher={OSF},\n  author={Schmellenkamp, Marko},\n  year={2022},\n  month={Dec},\n  note = {Last Access: 5 February, 2024}, \n}",
    "title": "Discovering Misconceptions in formal methods using ITS",
    "creator": "Schmellenkamp, Marko",
    "given_name": "Marko",
    "family_name": "Schmellenkamp",
    "name_identifier": "https://orcid.org/0000-0003-3966-6590",
    "affiliation": "Ruhr University Bochum",
    "availability": "open (trough signup with osf)",
    "format": "csv",
    "programming_language": null,
    "data_collection_start_date": 2019,
    "data_collection_end_date": 2022,
    "publication_year": 2022,
    "number_of_semesters": 3,
    "data_protection": "Anonymized",
    "data_type": "log data",
    "measurement_type": "logic statements, difficulty, popularity",
    "data_processing": "aggregate student attempts of the same session",
    "population": "students in a logic course ",
    "units_number": 50756,
    "task_number": 79,
    "sample_size": 0,
    "sample_demographics": "students in a logic course ",
    "country": "Germany",
    "educational_institution": "TU Dortmund University",
    "data_standard": null,
    "learning_environment": "Intelligent tutoring system: ILTIS",
    "aggregation": "Yes",
    "aggregation_level": "student attempts of the same session",
    "related_publication_url": "https://dl.acm.org/doi/10.1145/3545945.3569806",
    "related_publication": "\"@inproceedings{10.1145/3545945.3569806,\nauthor = {Schmellenkamp, Marko and Latys, Alexandra and Zeume, Thomas},\ntitle = {Discovering and Quantifying Misconceptions in Formal Methods Using Intelligent Tutoring Systems},\nyear = {2023},\nisbn = {9781450394314},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3545945.3569806},\ndoi = {10.1145/3545945.3569806},\nabstract = {In this paper we advocate the study of misconceptions in the formal methods domain by integrating quantitative and qualitative methods. In this domain, so far, misconceptions have mostly been studied with qualitative methods, typically via interviews with less than 20 subjects. We discuss workflows for (1) determining the commonness of qualitatively established misconceptions by quantitative means; and for (2) the initial discovery of misconceptions by quantitative methods followed by qualitative assessments.Parts of these workflows are then applied to a data set for exercises on logical modeling from the intelligent tutoring system Iltis with &gt; 250 data points for many of the exercises. We analyze the data in order to (1) determine the commonness of qualitativelyidentified misconceptions on modeling in propositional logic; and to (2) discover typical mistakes in modeling in propositional logic, modal logic, and first-order logic.},\nbooktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},\npages = {465–471},\nnumpages = {7},\nkeywords = {formal methods, first-order logic, propositional logic, modal logic, misconceptions, intelligent tutoring system},\nlocation = {Toronto ON, Canada},\nseries = {SIGCSE 2023}\n}\"",
    "rights": "CC-By Attribution 4.0 International",
    "description": "In this data repository we store the data for the paper Discovering and quantifying misconceptions in formal methods using intelligent tutoring systems. The paper describes a quantitative study to analyze candidates for misconceptions at modeling with propositional logic, modal logic, and first-order logic. For this, we use data from the intelligent tutoring system Iltis (https://iltis.cs.tu-dortmund.de).\n\nThis repository includes the following data:\n\nfor each type of logic, which statements were to be modeled and which operators they contained (see this page),\nfor each statement, its difficulty and popularity (see this page), and\nthe data for the analyses discussed in the paper, that is the difficulty of single linguistic operators and typical mistakes (see this page and this page).",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 52% (initial)\nFindability: 5 of 7\nAccessibility: 1.5 of 3\nInteroperability: 2 of 4\nReusability: 4 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "GitHub",
    "resource_url": "https://github.com/cyoon47/CS1QA",
    "resource_url_type": "URL",
    "bibtex_source": "@data{CS1QA,\n  title={CQ1QA},\n  url={https://github.com/cyoon47/CS1QA},\n  author={Changyoon Lee},\n  year={2022},\n  note = {Last Access: 5 February, 2024}, \n}",
    "title": "CS1QA",
    "creator": "Lee, Changyoon; Seonwoo, Yeon; Oh, Alice",
    "given_name": "Changyoon; Yeon; Alice",
    "family_name": "Lee; Seonwoo; Oh",
    "name_identifier": null,
    "affiliation": "Korea Advanced Institute of Science & Technology (KAIST)",
    "availability": "by request",
    "format": ".jsonl, .py, .sh, .txt",
    "programming_language": "Python",
    "data_collection_start_date": null,
    "data_collection_end_date": null,
    "publication_year": 2022,
    "number_of_semesters": 2,
    "data_protection": "Anonymized",
    "data_type": "log data",
    "measurement_type": "question-answer-code triples, chat logs",
    "data_processing": "annotation of question types and relevant code lines",
    "population": "programming course",
    "units_number": null,
    "task_number": 3,
    "sample_size": "9237 and 17698",
    "sample_demographics": "introductory programming class",
    "country": "South Korea",
    "educational_institution": "KAIST, School of Computing",
    "data_standard": null,
    "learning_environment": "elice, https://elice.io/en",
    "aggregation": "yes",
    "aggregation_level": "question-answer pairs",
    "related_publication_url": "https://arxiv.org/pdf/2210.14494.pdf",
    "related_publication": "@article{lee2022cs1qa,\n  title={CS1QA: A Dataset for Assisting Code-based Question Answering in an Introductory Programming Course},\n  author={Lee, Changyoon and Seonwoo, Yeon and Oh, Alice},\n  journal={arXiv preprint arXiv:2210.14494},\n  year={2022}\n}",
    "rights": "MIT License 2022 cyoon47",
    "description": "Repository for CS1QA: A Dataset for assisting Code-based Question Answering in an Introductory Programming Course, published at NAACL 2022\n\nThe annotated data can be found in this repository under the folder data. Due to the size of the unannotated chat and code data, we are unable to upload them to GitHub. If you want to get the data, please email the author at changyoon.lee@kaist.ac.kr.\n\nThe authors have made their best efforts to anonymize the data. However, there might be some personal or sensitive information left unfound in the dataset. By using the dataset, you agree to not abuse the personal or sensitive information that might be present in the dataset, and also notify the authors at changyoon.lee@kaist.ac.kr once you come across such data.",
    "research_question": "Develop a dataset containing questions about code",
    "future_work": "The dataset can be used as a benchmark for source code comprehension and question answering in the educational setting",
    "fairness_score": "Total score: 35% (initial)\nFindability: 2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 2 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Github",
    "resource_url": "https://github.com/jyi/ITSP#dataset-student-programs",
    "resource_url_type": "URL",
    "bibtex_source": "@data{ITSP_2017,\n  title={ITSP Dataset (Student Programs)},\n  url={https://github.com/jyi/ITSP#dataset-student-programs},\n  author={Jooyong Yi},\n  year={2017},\n  note = {Last Access: 5 February, 2024}, \n}",
    "title": "\nArtifacts of FSE-2017 paper on an Intelligent Tutoring System for Programming",
    "creator": "Yi, Jooyong; Ahmed, Umair Z.;  Karkare, Amey; Tan, Shin Hwei; Roychoudhury, Abhik",
    "given_name": "Jooyong; Umair; Amey; Shin Hwei; Abhik",
    "family_name": "Yi; Ahmed; Karkare; Tan; Roychoudhury",
    "name_identifier": null,
    "affiliation": null,
    "availability": "Publicly Availabl",
    "format": "Multiple: CSV, text and C files",
    "programming_language": "C",
    "data_collection_start_date": 2015,
    "data_collection_end_date": 2015,
    "publication_year": 2017,
    "number_of_semesters": 1,
    "data_protection": "No",
    "data_type": "Code Samples",
    "measurement_type": null,
    "data_processing": "Code I/O results",
    "population": 661,
    "units_number": null,
    "task_number": null,
    "sample_size": 661,
    "sample_demographics": "Students",
    "country": "India",
    "educational_institution": "Indian Institute of Technology Kanpur (IIT-K) ",
    "data_standard": null,
    "learning_environment": "Prutor",
    "aggregation": "Yes",
    "aggregation_level": "Submission",
    "related_publication_url": "https://dl.acm.org/doi/10.1145/3106237.3106262",
    "related_publication": "@inproceedings{10.1145/3106237.3106262,\nauthor = {Yi, Jooyong and Ahmed, Umair Z. and Karkare, Amey and Tan, Shin Hwei and Roychoudhury, Abhik},\ntitle = {A feasibility study of using automated program repair for introductory programming assignments},\nyear = {2017},\nisbn = {9781450351058},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3106237.3106262},\ndoi = {10.1145/3106237.3106262},\nabstract = {Despite the fact an intelligent tutoring system for programming (ITSP) education has long attracted interest, its widespread use has been hindered by the difficulty of generating personalized feedback automatically. Meanwhile, automated program repair (APR) is an emerging new technology that automatically fixes software bugs, and it has been shown that APR can fix the bugs of large real-world software. In this paper, we study the feasibility of marrying intelligent programming tutoring and APR. We perform our feasibility study with four state-of-the-art APR tools (GenProg, AE, Angelix, and Prophet), and 661 programs written by the students taking an introductory programming course. We found that when APR tools are used out of the box, only about 30\\% of the programs in our dataset are repaired. This low repair rate is largely due to the student programs often being significantly incorrect - in contrast, professional software for which APR was successfully applied typically fails only a small portion of tests. To bridge this gap, we adopt in APR a new repair policy akin to the hint generation policy employed in the existing ITSP. This new repair policy admits partial repairs that address part of failing tests, which results in 84\\% improvement of repair rate. We also performed a user study with 263 novice students and 37 graders, and identified an understudied problem; while novice students do not seem to know how to effectively make use of generated repairs as hints, the graders do seem to gain benefits from repairs.},\nbooktitle = {Proceedings of the 2017 11th Joint Meeting on Foundations of Software Engineering},\npages = {740–751},\nnumpages = {12},\nkeywords = {Intelligent Tutoring System, Automated Program Repair},\nlocation = {Paderborn, Germany},\nseries = {ESEC/FSE 2017}\n}\n\n",
    "rights": null,
    "description": "In our ESEC/FSE-17 paper titled A Feasibility Study of Using Automated Program Repair for Introductory Programming Assignments, we apply four state-of-the-art automated program repair (APR) tools to student programs collected from an Introductory C Programming course (CS-101) offered in Indian Institute of Technology Kanpur (IIT-K). To overcome the low repair rate of APR tools (due to that student programs are often severely incorrect), we introduce a new repair policy and strategy tailored to programming tutoring (described in Section 6 of our paper), which is implemented in our toolchain. In this repository, we share the artifacts we used in our study. Our artifacts consist of (1) dataset containing student programs, (2) toolchain, and (3) user study materials (we conducted a user study with students and teaching assistants to see the feasibility of using APR tools).\n\n",
    "research_question": "RQ1 How o_x0089_en are repairs generated when our partial repair\nalgorithm is employed in addition to the complete repair algorithm\nof the existing APR tools? A high repair rate is a prerequisite for\nusing APR for introductory programming assignments. _x008c_e current\nstate-of-the-art APR tools fail to generate repairs more o_x0089_en than\nnot, as shown in Section 4. How signi_x0080_cantly does a new repair\nstrategy allowing both complete and partial repairs improve repair\nrate?\nRQ2 When are repairs not generated even a_x0089_er employing our\npartial repair algorithm? If there are common reasons for those\ncases of repair failure, they should be addressed in future tools.\nRQ3 Do tool-generated partial repairs help students in _x0080_nding a\nsolution more e_x0081_ciently than when repairs are not shown?\nRQ4 Similarly, do tool-generated repairs help graders in grading student programs more e_x0081_ciently than when repairs are not\nshown?",
    "future_work": "Study\nof e_x0082_ective post-processing of repairs to transform them to hints\nmore comprehensible to novice students.",
    "fairness_score": "Total score: 27% (initial)\nFindability: 2.5 of 7\nAccessibility: 1 of 3\nInteroperability: 0 of 4\nReusability: 3 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zeondo",
    "resource_url": "https://doi.org/10.5281/zenodo.7799972",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{liliya_a_demidova_2023_7799972,\n  author       = {Liliya A. Demidova and\n                  Elena G. Andrianova and\n                  Peter N. Sovietov and\n                  Artyom V. Gorchakov},\n  title        = {{Dataset of Program Source Codes Solving Unique \n                   Programming Exercises Generated by Digital\n                   Teaching Assistant}},\n  month        = apr,\n  year         = 2023,\n  publisher    = {Zenodo},\n  doi          = {10.5281/zenodo.7799972},\n  url          = {https://doi.org/10.5281/zenodo.7799972},\n  note = {Last Access: 5 February, 2024}, \n}",
    "title": "Dataset of Program Source Codes Solving Unique Programming Exercises Generated by Digital Teaching Assistant",
    "creator": "Demidova, Liliya A.; Andrianova, Elena G.; Sovietov, Peter N.;  Gorchakov, Artyom V.",
    "given_name": "Liliya A.;  Elena G.; Peter N.; Artyom V.",
    "family_name": "Demidova; Andrianova; Sovietov; Gorchakov",
    "name_identifier": "https://orcid.org/0000-0003-4516-3746; https://orcid.org/0000-0001-6418-6797; https://orcid.org/0000-0002-1039-2429; https://orcid.org/0000-0003-1977-8165",
    "affiliation": "MIREA - Russian Technology University",
    "availability": "open",
    "format": "csv",
    "programming_language": "Python",
    "data_collection_start_date": 2022,
    "data_collection_end_date": 2022,
    "publication_year": 2023,
    "number_of_semesters": 1,
    "data_protection": null,
    "data_type": "source codes",
    "measurement_type": null,
    "data_processing": null,
    "population": null,
    "units_number": 66553,
    "task_number": 11,
    "sample_size": null,
    "sample_demographics": null,
    "country": "Russia",
    "educational_institution": "MIREA – Russian Technological University",
    "data_standard": null,
    "learning_environment": "Digital Teaching Assistant (DTA)",
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": null,
    "related_publication": "@Article{data8060109,\nAUTHOR = {Demidova, Liliya A. and Andrianova, Elena G. and Sovietov, Peter N. and Gorchakov, Artyom V.},\nTITLE = {Dataset of Program Source Codes Solving Unique Programming Exercises Generated by Digital Teaching Assistant},\nJOURNAL = {Data},\nVOLUME = {8},\nYEAR = {2023},\nNUMBER = {6},\nARTICLE-NUMBER = {109},\nURL = {https://www.mdpi.com/2306-5729/8/6/109},\nISSN = {2306-5729},\nABSTRACT = {This paper presents a dataset containing automatically collected source codes solving unique programming exercises of different types. The programming exercises were automatically generated by the Digital Teaching Assistant (DTA) system that automates a massive Python programming course at MIREA&mdash;Russian Technological University (RTU MIREA). Source codes of the small programs grouped by the type of the solved task can be used for benchmarking source code classification and clustering algorithms. Moreover, the data can be used for training intelligent program synthesizers or benchmarking mutation testing frameworks, and more applications are yet to be discovered. We describe the architecture of the DTA system, aiming to provide detailed insight regarding how and why the dataset was collected. In addition, we describe the algorithms responsible for source code analysis in the DTA system. These algorithms use vector representations of programs based on Markov chains, compute pairwise Jensen&ndash;Shannon divergences of programs, and apply hierarchical clustering algorithms in order to automatically discover high-level concepts used by students while solving unique tasks. The proposed approach can be incorporated into massive programming courses when there is a need to identify approaches implemented by students.},\nDOI = {10.3390/data8060109}\n}",
    "rights": "Creative Commons Attribution 4.0 International",
    "description": "The programming exercises were automatically generated by the Digital \nTeaching Assistant (DTA) system that automates a massive Python \nprogramming course at MIREA – Russian Technological University (RTU \nMIREA). Source codes of the small programs grouped by the type of the \nsolved task can be used for benchmarking source code classification and \nclustering algorithms. Moreover, the data can be used for training \nintelligent program synthesizers, or benchmarking mutation testing \nframeworks, and more applications are yet to be discovered. This dataset\n is a supplementary material for a paper entitled Dataset of Program Source Codes Solving Unique Programming Exercises Generated by Digital Teaching Assistant submitted to the MDPI Data journal.",
    "research_question": null,
    "future_work": null,
    "fairness_score": "Total score: 66% (moderate)\nFindability: 6 of 7\nAccessibility: 2 of 3\nInteroperability: 3 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "Zenodo",
    "resource_url": "https://doi.org/10.5281/zenodo.7489244",
    "resource_url_type": "DOI",
    "bibtex_source": "@data{el_hamamsy_2023_7489244,\n  author       = {El-Hamamsy, Laila and\n                  Bruno, Barbara and\n                  Dehler Zufferey, Jessica and\n                  Mondada, Francesco},\n  title        = {{Dataset for the evaluation of student-level \n                   outcomes of a primary school Computer Science\n                   curricular reform}},\n  month        = jun,\n  year         = 2023,\n  publisher    = {Zenodo},\n  doi          = {10.5281/zenodo.7489244},\n  url          = {https://doi.org/10.5281/zenodo.7489244}\n}",
    "title": "Dataset for the evaluation of student-level outcomes of a primary school Computer Science curricular reform",
    "creator": "El-Hamamsy, Lail; Bruno, Barbara; Dehler Zufferey, Jessica; Mondada, Francesco",
    "given_name": "Lail; Barbara; Jessica; Francesco",
    "family_name": "El-Hamamsy; Bruno; Dehler Zufferey; Mondada",
    "name_identifier": "https://orcid.org/0000-0002-6046-4822; https://orcid.org/0000-0003-0953-7173; https://orcid.org/0000-0001-5163-807X; https://orcid.org/0000-0001-8641-8704",
    "affiliation": "EPFL",
    "availability": "Open",
    "format": "csv",
    "programming_language": null,
    "data_collection_start_date": 2021,
    "data_collection_end_date": 2022,
    "publication_year": 2023,
    "number_of_semesters": 3,
    "data_protection": "Anonymized",
    "data_type": "students' responses to preception surveys",
    "measurement_type": "survey",
    "data_processing": 0,
    "population": "Grades 3-6 and teachers",
    "units_number": 5570,
    "task_number": 0,
    "sample_size": 5781,
    "sample_demographics": "USA",
    "country": "USA",
    "educational_institution": 0,
    "data_standard": null,
    "learning_environment": null,
    "aggregation": null,
    "aggregation_level": null,
    "related_publication_url": "El-Hamamsy et al. 2023",
    "related_publication": "@misc{elhamamsy2023primary,\n      title={How are Primary School Computer Science Curricular Reforms Contributing to Equity? Impact on Student Learning, Perception of the Discipline, and Gender Gaps}, \n      author={Laila El-Hamamsy and Barbara Bruno and Catherine Audrin and Morgane Chevalier and Sunny Avry and Jessica Dehler Zufferey and Francesco Mondada},\n      year={2023},\n      eprint={2306.00820},\n      archivePrefix={arXiv},\n      primaryClass={cs.CY}\n}",
    "rights": "CC BY 4.0 (Creative Commons Attribution 4.0 International)",
    "description": "Student learning and perception data from three studies with respectively 1384, 2433 and 1644 grade 3-6 students (ages 7-11) and their 83, 142 and 95 teachers.",
    "research_question": "How does the introduction of CS & CT into primary school curricula impact learning, perception, and gaps between groups of students?",
    "future_work": null,
    "fairness_score": "Total score: 66% (moderate)\nFindability: 5 of 7\nAccessibility: 2 of 3\nInteroperability: 4 of 4\nReusability: 5 of 10"
  },
  {
    "catalog_type": "DatasetCatalog",
    "publisher": "OSF",
    "resource_url": "https://osf.io/3c9mw/",
    "resource_url_type": "URL",
    "bibtex_source": "@data{Finke_Kemeny_Sommer_Krnjic_Arendasy_Slany_Landerl_2022,\n  title={Unravelling the Numerical and Spatial Underpinnings of Computational Thinking: A Pre-Registered Replication Study},\n  url={https://osf.io/3c9mw/},\n  publisher={OSF},\n  author={Finke, Sabrina and Kemeny, Ferenc and Sommer, Markus and Krnjic, Vesna and Arendasy, Martin and Slany, Wolfgang and Landerl, Karin},\n  year={2022},\n  month={May},\n  note = {Last Access: 5 February, 2024}, \n}",
    "title": "Unravelling the numerical and spatial underpinnings of computational thinking: a pre-registered replication study",
    "creator": "Finke, Sabrina; Kemeny, Ferenc; Sommer, Markus; Krnjic, Vesna; Arendasy, Martin; Slany, Wolfgang; Landerl, Karin",
    "given_name": "Sabrina; Ferenc; Markus; Vesna; Martin; Wolfgang; Karin",
    "family_name": "Finke; Kemeny; Sommer; Krnjic; Arendasy; Slany; Landerl",
    "name_identifier": "http://orcid.org/0000-0001-6260-2996; http://orcid.org/0000-0003-4074-0233;",
    "affiliation": "Austria",
    "availability": "Open",
    "format": "csv",
    "programming_language": "N/A (this study is on computational thinking in schools)",
    "data_collection_start_date": 2021,
    "data_collection_end_date": 2022,
    "publication_year": 2022,
    "number_of_semesters": 1,
    "data_protection": "anonymized",
    "data_type": "student performance data on a varety of tests",
    "measurement_type": "performance test",
    "data_processing": null,
    "population": "grade 7 and 8 students",
    "units_number": 132,
    "task_number": "3 school lessons",
    "sample_size": 132,
    "sample_demographics": "Grades 7 - 8 school",
    "country": "Austria",
    "educational_institution": "Institute of Psychology, University of Graz, Austria",
    "data_standard": null,
    "learning_environment": "A omputation thinking exam (multiple-choice test) mainly consists of logical and visuo-spatial problems",
    "aggregation": "yes",
    "aggregation_level": null,
    "related_publication_url": "Finke 2022",
    "related_publication": "\n@article{doi:10.1080/08993408.2022.2079864,\nauthor = {Sabrina Finke, Ferenc Kemény, Markus Sommer, Vesna Krnjic, Martin Arendasy, Wolfgang Slany and Karin Landerl},\ntitle = {Unravelling the numerical and spatial underpinnings of computational thinking: a pre-registered replication study},\njournal = {Computer Science Education},\nvolume = {32},\nnumber = {3},\npages = {313-334},\nyear = {2022},\npublisher = {Routledge},\ndoi = {10.1080/08993408.2022.2079864}, \nURL = {   \n        https://doi.org/10.1080/08993408.2022.2079864\n}, }",
    "rights": "openly available under OSFCreative Commons Attribution-NonCommercial-NoDerivatives License (http://creativecommons.org/licenses/by-nc-nd/4.0/)",
    "description": null,
    "research_question": "what factors/skills contribute to cognitive mechanism underlying Computational Thinking (CT) in students with no prior programming backgrounds?",
    "future_work": null,
    "fairness_score": "Total score: 33% (initial)\nFindability: 3 of 7\nAccessibility: 1 of 3\nInteroperability: 1 of 4\nReusability: 3 of 10"
  }
]